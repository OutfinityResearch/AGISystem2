<!doctype html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>AGISystem2 – Saturation Evaluation (HDC Strategy Capacity)</title>
  <link rel="stylesheet" href="../reference/style.css">
  <style>
    h2 {
      border-bottom: 2px solid #1976d2;
      padding-bottom: 10px;
      margin-top: 40px;
    }
    .abstract {
      background: #e3f2fd;
      padding: 20px;
      border-radius: 8px;
      margin: 20px 0;
      line-height: 1.6;
    }
    .callout {
      background: #fff3e0;
      border-left: 4px solid #ff9800;
      padding: 15px 20px;
      margin: 20px 0;
      border-radius: 0 8px 8px 0;
    }
    .success {
      background: #e8f5e9;
      border-left: 4px solid #4caf50;
      padding: 15px 20px;
      margin: 20px 0;
      border-radius: 0 8px 8px 0;
    }
    .mono {
      background: #f5f5f5;
      padding: 16px;
      border-radius: 8px;
      overflow-x: auto;
      font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace;
      font-size: 13px;
      line-height: 1.45;
    }
    .grid {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(240px, 1fr));
      gap: 16px;
      margin: 20px 0;
    }
    .card {
      background: #fff;
      border: 1px solid #e5e7eb;
      border-radius: 12px;
      padding: 16px 18px;
      box-shadow: 0 2px 10px rgba(0,0,0,0.06);
    }
    .card h3 {
      margin: 0 0 8px 0;
      font-size: 15px;
      color: #1976d2;
    }
    .pill {
      display: inline-block;
      padding: 3px 10px;
      border-radius: 999px;
      font-size: 11px;
      font-weight: 700;
      text-transform: uppercase;
      background: #e3f2fd;
      color: #1565c0;
      margin-left: 8px;
    }
    table {
      width: 100%;
      border-collapse: collapse;
      margin: 16px 0;
      font-size: 14px;
    }
    th, td {
      border: 1px solid #ddd;
      padding: 10px 12px;
      text-align: left;
      vertical-align: top;
    }
    th {
      background: #1976d2;
      color: white;
    }
    tr:nth-child(even) { background: #fafafa; }
    .pass { color: #2e7d32; font-weight: 700; }
    .fail { color: #c62828; font-weight: 700; }
    .muted { color: #666; }
  </style>
</head>
<body>
  <div class="page">
  <div class="nav-header">
    <h1>Saturation Evaluation <span class="pill">Research</span></h1>
    <small>
      <a href="../index.html">Home</a> ·
      <a href="../architecture/index.html">Architecture</a> ·
      <a href="../theory/index.html">Theory</a> ·
      <a href="../syntax/index.html">Syntax</a> ·
      <a href="../api/index.html">APIs</a> ·
      <a href="../specs/matrix.html">Specs</a> ·
      <a href="index.html"><strong>Research</strong></a>
    </small>
    <small>Capacity and saturation behavior of holographic queries under hierarchical superposition</small>
  </div>

  <div class="abstract">
    <strong>Abstract.</strong> This document describes the AGISystem2 saturation evaluation suite
    (<code>evals/runSaturationEval.mjs</code>), designed to measure how quickly different HDC strategies
    lose discriminative power when many facts are superposed into a single composite representation.
    We construct synthetic “books” as hierarchical bundles (records → chapters → book) and test whether
    the resulting <code>@Book</code> vector supports <em>pure holographic</em> membership queries via the
    reasoning equation <code>UNBIND(Book, QueryKey)</code>, alongside symbolic query validation.
    The suite is explicitly comparative: classic probabilistic VSA strategies are measured against
    the lossless <strong>EXACT</strong> strategy, which provides an upper bound on retrievability.
  </div>

  <h2>1. What “Saturation” Means Here</h2>

  <p>
    In HDC/VSA systems, a bundle/superposition combines many items into one vector. As the number of bundled
    items grows, the composite vector may become less discriminative: unrelated candidates can become “accidentally”
    similar to a query, increasing ambiguity and false positives. We refer to this effect as <strong>saturation</strong>.
  </p>

  <div class="callout">
    <strong>Key idea:</strong> the suite does not test “can the symbolic engine answer the query?” (it usually can),
    but “can the <code>@Book</code> composite alone support retrieval via UNBIND + cleanup?”
  </div>

  <h2>2. Data Model: Books, Chapters, Ideas, and Records</h2>

  <p>The suite uses DSL files in <code>evals/saturation/books/</code> to simulate books:</p>

  <div class="grid">
    <div class="card">
      <h3>Records (facts)</h3>
      <p class="muted">
        Index-like facts that connect a book identifier, a key, and an idea.
      </p>
      <div class="mono">Mentions Book02 Key_B02_C04_I02 ActionSequencing</div>
    </div>
    <div class="card">
      <h3>Chapters</h3>
      <p class="muted">
        Content is a bundle of record vectors. Optional ordered structure is kept separately.
      </p>
      <div class="mono">@Chapter04:Chapter04 bundle [$B02_R0007, $B02_R0008]</div>
    </div>
    <div class="card">
      <h3>Book</h3>
      <p class="muted">
        Book content is a bundle of chapter content vectors (hierarchical superposition).
      </p>
      <div class="mono">@Book:Book bundle [$Chapter01, ..., $Chapter04]</div>
    </div>
  </div>

  <h2>3. Why We Keep <code>_Seq</code> Variables (Structure vs. Membership)</h2>

  <p>
    Real books have order (ideas in a chapter; chapters in a book). In AGISystem2, the structural operator
    <code>__Sequence</code> builds an ordered superposition by binding each element to a position marker
    (<code>Pos1</code>, <code>Pos2</code>, …) before bundling.
  </p>

  <div class="mono">@Chapter04_Seq __Sequence [$B02_R0007, $B02_R0008]
@Chapter04:Chapter04 bundle [$B02_R0007, $B02_R0008]</div>

  <p>
    For saturation testing we need a <em>membership-oriented</em> representation: the <code>@Book</code> vector
    should behave like a superposition of queryable records. If we used <code>__Sequence</code> everywhere, the
    “book content” would be expressed in a different algebra (everything becomes “positioned”), and the simple
    fact-unbinding pattern would no longer reflect the intended query semantics.
  </p>

  <div class="success">
    <strong>Design choice:</strong> keep ordered structure as <code>*_Seq</code> metadata, while using pure
    <code>bundle</code> for <code>@ChapterNN</code> and <code>@Book</code> content vectors.
  </div>

  <h2>4. Query Protocol (Two Holographic Tests + Symbolic Validation)</h2>

  <p>
    Each book file contains two markers parsed by the runner:
  </p>
  <div class="mono"># SAT_QUERY_POS op=Mentions book=Book02 key=Key_B02_C04_I02 expect=ActionSequencing
# SAT_QUERY_NEG op=Mentions book=Book02 key=Key_B02_Missing expect=none</div>

  <h3>4.1 Holographic decode A: (book, key) → idea</h3>
  <p>
    We treat <code>Mentions(book, key, idea)</code> as a 3-argument record with positional encoding (Pos1..Pos3).
    For a query where <code>book</code> and <code>key</code> are known, we compute a query key and unbind:
  </p>
  <div class="mono">partial = Mentions BIND (Book BIND Pos1) BIND (Key BIND Pos2)
answer  = UNBIND(BookVector, partial)
ideaVec = UNBIND(answer, Pos3)</div>
  <p>
    The recovered <code>ideaVec</code> is then “cleaned up” by ranking against a bounded candidate set.
  </p>

  <h3>4.2 Holographic decode B: (book, idea) → key (membership test)</h3>
  <p>
    To approximate the question “is this idea in the book?”, we invert the missing slot:
  </p>
  <div class="mono">partial = Mentions BIND (Book BIND Pos1) BIND (Idea BIND Pos3)
answer  = UNBIND(BookVector, partial)
keyVec  = UNBIND(answer, Pos2)</div>
  <p>
    If the idea is not present, the decoded key should not match any real key confidently.
  </p>

  <h3>4.3 Candidate sets (cleanup) simulate a reverse-index</h3>
  <p>
    Pure holographic decode typically needs cleanup against a candidate set. The runner simulates a “reverse-index
    narrowed” candidate pool of fixed size (default 10):
  </p>
  <ul>
    <li><strong>POS:</strong> candidates are mostly real in-book ideas/keys (as if the reverse index hit)</li>
    <li><strong>NEG:</strong> candidates are decoys only (as if the reverse index miss)</li>
  </ul>

  <h3>4.4 Symbolic validation</h3>
  <p>
    In parallel, the suite validates correctness via the query engine:
  </p>
  <div class="mono">@q Mentions Book02 Key_B02_C04_I02 ?idea
@q Mentions Book02 ?key ActionSequencing</div>
  <p>
    This ensures that failures in holographic decode are interpreted as saturation effects (representation/geometry),
    not “missing knowledge”.
  </p>

  <h2>5. Running the Suite and Interpreting Outputs</h2>

  <div class="mono">node evals/runSaturationEval.mjs
node evals/runSaturationEval.mjs --full
node evals/runSaturationEval.mjs --huge
node evals/runSaturationEval.mjs --extra-huge
node evals/runSaturationEval.mjs --strategies=dense-binary,metric-affine,metric-affine-elastic,exact
node evals/runSaturationEval.mjs --priority=holographicPriority
node evals/runSaturationEval.mjs --no-color</div>

  <h3>5.1 Suite modes (geometry sweeps)</h3>
  <p class="muted">
    Each strategy has its own “geometry” meaning (bits for Dense-Binary, k for Sparse-Polynomial, bytes for Metric, etc.).
    The suite provides fast/full/huge/extra-huge presets to explore scaling without changing code.
  </p>

  <h3>5.2 Summary metrics</h3>
  <p>The runner prints a summary table with (names may vary by mode):</p>
  <table>
    <tr>
      <th>Column</th>
      <th>Meaning</th>
      <th>Why it matters for saturation</th>
    </tr>
    <tr>
      <td><code>HDC</code></td>
      <td>Holographic decode A pass rate (book,key→idea)</td>
      <td>Measures retrieval from the composite alone</td>
    </tr>
    <tr>
      <td><code>HMem</code></td>
      <td>Holographic membership pass rate (book,idea→key)</td>
      <td>Direct proxy for “idea ∈ book?”</td>
    </tr>
    <tr>
      <td><code>Query</code>, <code>QMem</code></td>
      <td>Symbolic validation pass rates</td>
      <td>Ground truth: should usually pass unless the DSL is wrong</td>
    </tr>
    <tr>
      <td><code>AvgPosM</code>, <code>AvgNegM</code></td>
      <td>Average margin (top1-top2 similarity) for POS/NEG</td>
      <td>Lower margins indicate ambiguity and approach to saturation</td>
    </tr>
    <tr>
      <td><code>SimChk</code></td>
      <td>Similarity checks performed during cleanup</td>
      <td>Cost proxy: cleanup is O(|candidates|)</td>
    </tr>
    <tr>
      <td><code>UnbChk</code> (EXACT)</td>
      <td>Operation count proxy for polynomial unbind (subset checks)</td>
      <td>EXACT cost scales with number of terms in the composite</td>
    </tr>
    <tr>
      <td><code>Time</code></td>
      <td>Total per-config time (learn+decode)</td>
      <td>Throughput comparison across strategies</td>
    </tr>
  </table>

  <h3>5.3 Pass criteria (avoiding “tie passes”)</h3>
  <p>
    In saturation experiments it is easy to accidentally count a decode as “correct” even when the representation carries no usable signal
    (e.g., every candidate has similarity 0.000, and the ranking depends on iteration order). To ensure the suite measures real retrieval,
    the runner uses a strict positive criterion and a conservative negative criterion:
  </p>
  <ul>
    <li><strong>POS:</strong> the expected item must be <em>top-1</em>, with <code>top1Sim &gt; 0</code>, and <code>top1Sim &gt; top2Sim</code> (a non-zero margin).</li>
    <li><strong>NEG:</strong> the best candidate must remain below the strategy’s configured “match” threshold (<code>HDC_MATCH(strategy)</code>), to avoid confident hallucinations.</li>
  </ul>
  <p class="muted">
    Consequence: symbolic queries can be 100% correct while holographic decode reports failures—this is expected and indicates saturation or
    threshold mismatch, not missing data.
  </p>

  <h2>6. Why Results Differ Across Strategies and Parameters</h2>

  <h3>6.1 Geometry and capacity</h3>
  <p>
    Higher geometry typically increases capacity (more nearly-orthogonal space), delaying saturation.
    However, strategies differ in how “capacity” manifests:
  </p>
  <ul>
    <li><strong>Dense-Binary:</strong> saturation appears as accidental similarity; small geometries can hallucinate on NEG (false positives).</li>
    <li><strong>Sparse-Polynomial:</strong> capacity relates to k (sparsity); larger k can increase discrimination but may become slower.</li>
    <li><strong>Metric-Affine / EMA:</strong> similarity baselines differ (byte-channel overlap); thresholds are tuned differently and can be stricter.</li>
    <li><strong>EXACT:</strong> lossless set/polynomial encoding can yield perfect matches; it acts as an upper bound on retrievability, not a noisy VSA.</li>
  </ul>

  <h3>6.2 Strategy-specific UNBIND semantics</h3>
  <p>
    In XOR-based strategies, <code>UNBIND</code> is often implemented by <code>BIND</code> again (cancellation).
    In <strong>EXACT</strong>, <code>UNBIND</code> is quotient-like: it searches for residual terms consistent with the component.
    The saturation suite runs both default modes:
  </p>
  <ul>
    <li><strong>EXACT(A):</strong> existential quotient (emit residuals for matches)</li>
    <li><strong>EXACT(B):</strong> residual intersection across component terms (stricter)</li>
  </ul>
  <p class="muted">
    In this suite, most <code>UNBIND</code> calls use single-term components, so A/B are often similar; differences emerge in multi-term unbinding workloads.
  </p>

  <h3>6.3 Why symbolic queries can pass while holographic decode fails</h3>
  <p>
    Symbolic query engines use structured metadata and indexes over persisted facts. They can answer a query
    even when the holographic composite saturates, because they do not rely on approximate similarity in a single
    bundled representation. In contrast, holographic decode is intentionally “index-less” and therefore sensitive
    to saturation.
  </p>

  <h2>7. Book Families and Scaling Axes</h2>

  <p>The suite includes multiple book families to test different scaling regimes:</p>
  <ul>
    <li><code>book01..book30</code>: increase chapters while keeping ideas/chapter fixed (hierarchical depth/size)</li>
    <li><code>book_10cap_100</code>, <code>book_10cap_1000</code>: keep chapters fixed (10) but scale ideas/chapter and per-idea “width” (record density)</li>
  </ul>

  <div class="callout">
    <strong>Interpretation:</strong> different scaling axes saturate strategies differently. Increasing “ideas per chapter”
    increases local bundle density; increasing “per-idea width” increases the number of facts and tokens competing in the same composite.
  </div>

  <h2>8. Practical Reading of Variations</h2>

  <p>
    When comparing runs across presets (<code>--fast</code>/<code>--full</code>/<code>--huge</code>/<code>--extra-huge</code>), interpret changes as follows:
  </p>
  <ul>
    <li><strong>More geometry</strong> usually increases separation between candidates (higher POS margin, lower NEG confidence), but the effect is strategy-dependent.</li>
    <li><strong>Hierarchical depth</strong> (<code>book01..book30</code>) primarily increases the total number of superposed records, stressing bundling capacity.</li>
    <li><strong>Local density</strong> (<code>book_10cap_*</code>) increases collisions within each chapter bundle, which can degrade cleanup margins earlier.</li>
    <li><strong>Threshold tuning</strong> matters: strategies with conservative similarity thresholds may report failures even when rankings are qualitatively “close”.</li>
    <li><strong>EXACT</strong> serves as an upper bound: if EXACT cannot retrieve, the encoding/query protocol is inconsistent (a modeling bug, not saturation).</li>
  </ul>

  <div class="footer-nav">
    <p><strong>Related:</strong></p>
    <ul>
      <li><a href="index.html">Research Index</a></li>
      <li><a href="../theory/index.html">Theory: Bind / Unbind / Bundle</a></li>
      <li><a href="../theory/strategies/exact.html">EXACT Strategy</a></li>
      <li><a href="benchmarks.html">External Benchmarks</a></li>
    </ul>
    <p><a href="../index.html">← Back to Documentation Home</a></p>
  </div>
  </div>
</body>
</html>
