<!doctype html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Research – Dynamic Size HDC Representations</title>
  <link rel="stylesheet" href="../reference/style.css">
  <style>
    .callout {
      background: #e3f2fd;
      border-left: 4px solid #1976d2;
      padding: 14px 18px;
      border-radius: 0 10px 10px 0;
      margin: 18px 0;
    }
    .warn {
      background: #fff3e0;
      border-left: 4px solid #ff9800;
      padding: 14px 18px;
      border-radius: 0 10px 10px 0;
      margin: 18px 0;
    }
    .grid {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(260px, 1fr));
      gap: 14px;
      margin: 18px 0;
    }
    .card {
      background: #fff;
      border: 1px solid #e5e7eb;
      border-radius: 12px;
      padding: 14px 16px;
      box-shadow: 0 2px 10px rgba(0,0,0,0.06);
    }
    .card h3 {
      margin: 0 0 8px 0;
      color: #1976d2;
      font-size: 15px;
    }
    .card p {
      margin: 0;
      color: #555;
      font-size: 13px;
      line-height: 1.45;
    }
    table { width: 100%; border-collapse: collapse; margin: 18px 0; }
    th, td { border: 1px solid #ddd; padding: 10px 12px; text-align: left; }
    th { background: #1976d2; color: white; }
    code { font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace; }
  </style>
</head>
<body>
  <div class="page">
    <div class="nav-header">
      <h1>Dynamic Size Representations (Research Theme)</h1>
      <small>
        <a href="../index.html">Home</a> ·
        <a href="../architecture/index.html">Architecture</a> ·
        <a href="../theory/index.html">Theory</a> ·
        <a href="../specs/matrix.html">Specs</a> ·
        <a href="index.html">Research</a> ·
        <a href="dynamic-size-representations.html"><strong>Dynamic Size</strong></a>
      </small>
      <small>Why “elastic” representations matter for capacity, determinism, and long-running sessions</small>
    </div>

    <div class="callout">
      <strong>Definition (in this project):</strong> a “dynamic size” (or “elastic geometry”) HDC representation is one where the
      effective vector width can <em>grow</em> as new atoms appear, without forcing a global re-encode of previously loaded theories.
      The critical property is <strong>prefix stability</strong>: earlier encodings remain valid when the representation expands.
    </div>

    <h2 style="margin-top: 0;">Why this is important</h2>
    <p>
      Many VSA/HDC systems choose a fixed dimension (e.g. 2048–16384 bits) and accept that large knowledge bases eventually reduce
      retrievability due to superposition noise. In AGISystem2 we want to study what happens when we remove (or relax) that fixed
      geometry constraint and allow the representation to grow with the knowledge base.
    </p>

    <div class="grid">
      <div class="card">
        <h3>Capacity under growth</h3>
        <p>
          When KB size increases, “one fixed dimension” forces a trade-off between speed and collision/noise. Elastic size lets us
          explore a different trade-off: pay additional bytes/bits only when the universe expands.
        </p>
      </div>
      <div class="card">
        <h3>Determinism across runs</h3>
        <p>
          Evaluators often run many sessions sequentially in the same Node process. A session-local allocator plus elastic geometry
          keeps results reproducible without relying on a process-global dictionary.
        </p>
      </div>
      <div class="card">
        <h3>Reasoning ergonomics</h3>
        <p>
          “Exact-ish” witnesses (role markers, position atoms, operator families) become easier to detect when the representation can
          preserve structure and avoid destructive compression.
        </p>
      </div>
    </div>

    <h2>Strategies in AGISystem2 that support dynamic size</h2>

    <table>
      <tr>
        <th>Strategy</th>
        <th>What grows</th>
        <th>Why it helps</th>
        <th>Spec</th>
      </tr>
      <tr>
        <td><strong>Metric-Affine Elastic (EMA)</strong></td>
        <td>Byte geometry grows by chunks</td>
        <td>Superposition stays usable under larger KBs; bundling can be chunk-aware</td>
        <td><a href="../specsLoader.html?spec=DS/DS23-Elastic-Metric-Affine-HDC.md">DS23</a></td>
      </tr>
      <tr>
        <td><strong>EXACT</strong></td>
        <td>BigInt bitsets naturally extend to higher bit indices</td>
        <td>Lossless membership / witness extraction; upper bound for retrievability</td>
        <td><a href="../specsLoader.html?spec=DS/DS25-Exact-Sparse-Bitset-Polynomial-HDC.md">DS25</a></td>
      </tr>
      <tr>
        <td><strong>Sparse-Polynomial</strong></td>
        <td>Exponent set space is not tied to a fixed bit-width</td>
        <td>Compact storage at low <code>k</code>; useful baseline for “growth without fixed dimension”</td>
        <td><a href="../specsLoader.html?spec=DS/DS15-Sparse-Polynomial-HDC.md">DS15</a></td>
      </tr>
      <tr>
        <td><strong>Dense-Binary (baseline)</strong></td>
        <td>Does not grow (fixed bits)</td>
        <td>Reference point for classic HRR/VSA behavior</td>
        <td><a href="../specsLoader.html?spec=DS/DS09-Core-HDC-Implementation.md">DS09</a></td>
      </tr>
      <tr>
        <td><strong>Metric-Affine (fixed)</strong></td>
        <td>Typically fixed bytes per vector</td>
        <td>Fast baseline for byte-channel geometry before adding elasticity</td>
        <td><a href="../specsLoader.html?spec=DS/DS18-Metric-Affine-HDC.md">DS18</a></td>
      </tr>
    </table>

    <div class="warn">
      <strong>Important:</strong> “dynamic size” does not automatically mean “more accurate”.
      It changes the cost model (time/memory) and the failure modes. A major research question is when elastic growth is worth it,
      and when a fixed geometry + better cleanup/decoding is the better engineering choice.
    </div>

    <h2>Biological intuition (careful analogy)</h2>
    <p>
      We treat this as an analogy rather than a strict claim about neurobiology: biological systems do not appear to commit to a single
      global “vector width” that is fixed forever. Instead, coding capacity can be supported by:
    </p>
    <ul>
      <li><strong>Recruitment:</strong> more neurons/synapses participate as representations become richer.</li>
      <li><strong>Sparsity:</strong> information can be carried by sparse, distributed activity patterns.</li>
      <li><strong>Hierarchies:</strong> separate subsystems can encode at different “scales” (fast/approx vs slow/precise).</li>
    </ul>
    <p>
      In AGISystem2, EMA and EXACT are the “engineering analogs” of this idea: expand capacity as the KB grows, rather than fixing a
      dimension upfront and accepting progressive interference.
    </p>

    <h2>How we evaluate it</h2>
    <p>
      The main experimental harnesses are:
    </p>
    <ul>
      <li><a href="benchmarks.html">Benchmarks</a>: end-to-end correctness and timing across strategies/geometries.</li>
      <li><a href="saturationEvaluation.html">Saturation Evaluation</a>: controlled “superposition stress tests” (membership queries over synthetic books).</li>
    </ul>

    <h2>Open questions</h2>
    <ul>
      <li>How should “growth” be scheduled (linear, geometric, chunked) for best time/memory trade-offs?</li>
      <li>Can we expose “witness-level” hooks in strategy contracts to cut symbolic validation when safe?</li>
      <li>What is the best cleanup strategy when elastic representations still accumulate structured noise?</li>
    </ul>
  </div>
</body>
</html>

