<!doctype html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>AGISystem2 – NL→DSL LLM-Assisted Translation</title>
  <link rel="stylesheet" href="../../reference/style.css">
  <style>
    .research-section { background: #f5f5f5; padding: 20px; border-radius: 8px; margin: 20px 0; }
    .pattern-box { background: #e3f2fd; border-left: 4px solid #1976d2; padding: 15px 20px; margin: 15px 0; border-radius: 0 8px 8px 0; }
    .warning-box { background: #fff3e0; border-left: 4px solid #ff9800; padding: 15px 20px; margin: 15px 0; border-radius: 0 8px 8px 0; }
    .code-example { background: #263238; color: #aed581; padding: 15px; border-radius: 8px; font-family: monospace; overflow-x: auto; margin: 15px 0; }
    h2 { border-bottom: 2px solid #1976d2; padding-bottom: 10px; margin-top: 40px; }
    table { width: 100%; border-collapse: collapse; margin: 20px 0; }
    th, td { border: 1px solid #ddd; padding: 12px; text-align: left; }
    th { background: #1976d2; color: white; }
  </style>
</head>
<body>
  <div class="page">
  <div class="nav-header">
    <h1>NL→DSL LLM-Assisted Translation</h1>
    <small>
      <a href="../../index.html">Home</a> ·
      <a href="../index.html">Research</a> ·
      <a href="../roadmap.html">Roadmap</a>
    </small>
    <small>Using LLMs as intelligent preprocessors for complex natural language</small>
  </div>

  <div class="research-section">
    <h2 style="margin-top: 0; border: none;">Research Overview</h2>
    <p><strong>Goal:</strong> Leverage LLMs (Claude, GPT, etc.) to handle ambiguous, idiomatic, or context-dependent natural language before formal grammar parsing.</p>
    <p><strong>Principle:</strong> LLMs handle language understanding; AGISystem2 handles formal reasoning. Each does what it's best at.</p>
  </div>

  <h2>1. Integration Patterns</h2>

  <h3>Pattern A: Preprocessing Pipeline</h3>

  <div class="code-example">
<pre>
User Input (ambiguous)
        │
        ▼
┌───────────────────┐
│ LLM Preprocessor  │  ← Resolve ambiguity, expand context
└───────────────────┘
        │
        ▼
┌───────────────────┐
│ Grammar Parser    │  ← Parse normalized text
└───────────────────┘
        │
        ▼
┌───────────────────┐
│ AGISystem2        │  ← Formal reasoning
└───────────────────┘
</pre>
  </div>

  <h3>Pattern B: Fallback Translation</h3>

  <div class="code-example">
<pre>
User Input
        │
        ▼
┌───────────────────┐
│ Grammar Parser    │  ← Try grammar first
└───────────────────┘
        │
    ┌───┴───┐
    │Failed │
    └───┬───┘
        ▼
┌───────────────────┐
│ LLM Translation   │  ← LLM generates DSL directly
└───────────────────┘
        │
        ▼
┌───────────────────┐
│ DSL Validator     │  ← Validate LLM output
└───────────────────┘
</pre>
  </div>

  <h2>2. LLM Capabilities We Leverage</h2>

  <table>
    <tr>
      <th>Capability</th>
      <th>Use Case</th>
      <th>Example</th>
    </tr>
    <tr>
      <td><strong>Coreference Resolution</strong></td>
      <td>Resolve pronouns and references</td>
      <td>"John saw Mary. He waved." → "John waved"</td>
    </tr>
    <tr>
      <td><strong>Idiom Expansion</strong></td>
      <td>Convert idioms to literal meaning</td>
      <td>"It's raining cats and dogs" → "It's raining heavily"</td>
    </tr>
    <tr>
      <td><strong>Domain Terminology</strong></td>
      <td>Expand jargon and abbreviations</td>
      <td>"The patient has HTN" → "has hypertension"</td>
    </tr>
    <tr>
      <td><strong>Implicit Relations</strong></td>
      <td>Make implicit knowledge explicit</td>
      <td>"Paris is a capital" → "Paris is the capital of France"</td>
    </tr>
    <tr>
      <td><strong>Sentence Simplification</strong></td>
      <td>Break complex sentences</td>
      <td>"The tall man who wore a hat left" → "A man wore a hat. The man was tall. The man left."</td>
    </tr>
  </table>

  <h2>3. Prompt Engineering</h2>

  <div class="pattern-box">
    <strong>Preprocessing Prompt Template:</strong>
    <div class="code-example" style="background: #1a1a2e;">
<pre>
You are a natural language normalizer for a formal reasoning system.

Given this input text:
"${userInput}"

Transform it following these rules:
1. Resolve all pronouns to their referents
2. Expand abbreviations and acronyms
3. Convert idioms to literal meaning
4. Make implicit relations explicit
5. Split complex sentences into simple ones
6. Preserve all semantic content

Output the normalized text only, no explanations.
</pre>
    </div>
  </div>

  <div class="pattern-box">
    <strong>Direct DSL Translation Prompt:</strong>
    <div class="code-example" style="background: #1a1a2e;">
<pre>
Translate to AGISystem2 DSL:

DSL Syntax:
- isA Subject Type (taxonomy)
- has Subject Property (attributes)
- Implies $antecedent $consequent (rules)
- And $a $b, Or $a $b, Not (x) (logic)
- Variables: ?x, ?y (in rules)

Input: "${userInput}"

Output valid DSL only, one statement per line.
</pre>
    </div>
  </div>

  <h2>4. Validation & Trust Boundaries</h2>

  <div class="warning-box">
    <strong>Critical Principle:</strong> LLM output MUST be validated before use in reasoning.
    <ul>
      <li>DSL syntax validation (parser check)</li>
      <li>Semantic coherence check (no contradictions)</li>
      <li>Entity preservation (all mentioned entities present)</li>
      <li>No hallucinated operators or relations</li>
    </ul>
  </div>

  <div class="code-example">
<pre>
<span style="color: #78909c;">// Validation pipeline</span>
async function validateLLMOutput(dsl, originalInput) {
  <span style="color: #78909c;">// 1. Syntax check</span>
  const parseResult = parseDSL(dsl);
  if (parseResult.errors.length > 0) {
    return { valid: false, reason: 'syntax_error' };
  }

  <span style="color: #78909c;">// 2. Extract entities from input</span>
  const inputEntities = extractEntities(originalInput);

  <span style="color: #78909c;">// 3. Check all entities present in DSL</span>
  const dslEntities = extractDSLEntities(dsl);
  const missing = inputEntities.filter(e => !dslEntities.includes(e));
  if (missing.length > 0) {
    return { valid: false, reason: 'missing_entities', missing };
  }

  <span style="color: #78909c;">// 4. Check for unknown operators</span>
  const unknownOps = findUnknownOperators(dsl);
  if (unknownOps.length > 0) {
    return { valid: false, reason: 'unknown_operators', unknownOps };
  }

  return { valid: true };
}
</pre>
  </div>

  <h2>5. Hybrid Strategy</h2>

  <p>The optimal approach combines grammar-based and LLM-assisted translation:</p>

  <table>
    <tr>
      <th>Scenario</th>
      <th>Method</th>
      <th>Rationale</th>
    </tr>
    <tr>
      <td>Simple, structured input</td>
      <td>Grammar only</td>
      <td>Fast, deterministic, no API cost</td>
    </tr>
    <tr>
      <td>Contains pronouns/references</td>
      <td>LLM preprocessing → Grammar</td>
      <td>Resolve references, then parse</td>
    </tr>
    <tr>
      <td>Contains idioms/jargon</td>
      <td>LLM preprocessing → Grammar</td>
      <td>Normalize language, then parse</td>
    </tr>
    <tr>
      <td>Grammar parse fails</td>
      <td>LLM direct translation</td>
      <td>Fallback for unsupported patterns</td>
    </tr>
    <tr>
      <td>LLM translation fails validation</td>
      <td>Return error to user</td>
      <td>No unreliable output</td>
    </tr>
  </table>

  <h2>6. Research Questions</h2>

  <ul>
    <li><strong>Optimal prompt engineering:</strong> What prompts produce the most reliable DSL?</li>
    <li><strong>Error recovery:</strong> How to handle partial LLM failures?</li>
    <li><strong>Cost-accuracy tradeoff:</strong> When is LLM assistance worth the latency/cost?</li>
    <li><strong>Model selection:</strong> Which LLMs perform best for DSL translation?</li>
    <li><strong>Fine-tuning potential:</strong> Can we fine-tune smaller models for this task?</li>
  </ul>

  <h2>7. Related Work</h2>

  <ul>
    <li><a href="nl2dsl-grammar.html">Grammar-Based Translation</a> – Complementary approach</li>
    <li><a href="../../guides/llm-integration.html">LLM Integration Guide</a> – General LLM patterns</li>
    <li><a href="../../theory/nl2dsl.html">NL2DSL Theory</a> – Architecture overview</li>
  </ul>

  <div class="footer-nav">
    <p><a href="../roadmap.html">&larr; Back to Research Roadmap</a></p>
  </div>
  </div>
</body>
</html>
