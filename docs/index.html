<!doctype html>
<html>
<head>
  <meta charset="utf-8">
  <title>AGISystem2 – Vision & Guide</title>
  <link rel="stylesheet" href="style.css">
</head>
<body>
  <div class="page">
  <div class="nav-header">
    <h1>AGISystem2 – Vision & Guide</h1>
    <small>Deterministic neuro-symbolic geometry for explainable reasoning</small>
  </div>
  <div class="section-intro">
    <p>This is a long-form, human-readable guide to a deterministic neuro-symbolic engine. AGISystem2 thinks in geometry: concepts are regions, relations are rotations, and context is a stack of overlays. The goal of these pages is to explain why we chose this path, how it works, and how to use it safely. Expect essays, diagrams, and examples rather than terse checklists.</p>
  </div>

  <h2>Research & Technologies</h2>
  <p>This engine sits at the intersection of several research traditions: conceptual spaces, hyperdimensional computing, adversarial statistics, and practical software architecture for safety‑critical systems. If you are a programmer who has not specialised in machine learning, you can still read this documentation as a gentle introduction to those ideas. The core intuition is that we never manipulate raw text or opaque neural weights directly; instead we encode everything into a geometric space where every operation can be explained as a distance, a rotation, or a layered override. The chapters referenced below form a living wiki of concepts. When you see an unfamiliar term such as “bounded diamond”, “LSH index”, or “deontic band” in other pages, you can always come back here and follow the links to their extended explanations.</p>
  <p>The starting point for understanding the research foundations is the chapter on <a href="conceptual_spaces.html">Conceptual Spaces</a>, which explains how ideas from Peter Gärdenfors and related work are turned into concrete data structures such as int8 vectors, relevance masks, and unions of bounded diamonds. Closely related is the chapter on <a href="algorithms.html">Algorithms & Acronyms</a>, where techniques like locality‑sensitive hashing, vector permutations, temporal rotations, and superposition are described in plain language with engineering‑oriented intuition. For an overview of how reasoning itself becomes a sequence of geometric manipulations, you can read the <a href="reasoning.html">Reasoning</a> chapter, which connects classical notions like deduction, induction, abduction, and analogy to movement inside the conceptual space.</p>
  <p>Because the system is meant to be auditable and value‑aware, there are dedicated wiki‑style explanations for how facts, norms, and preferences are kept apart. The <a href="bias.html">Bias & Values</a> chapter introduces the separation between ontology dimensions, which carry factual content, and axiology dimensions, which express value judgements; it also shows how theory layers and masks can simulate different legal or cultural viewpoints without corrupting the underlying data. The <a href="explainability.html">Explainability</a> chapter focuses on how proofs, bands, provenance logs, and validation checks are generated and how they can be read by engineers or auditors who may not care about the underlying geometry as long as they can follow a deterministic trail of evidence. When documentation pages on API or configuration mention things like “adversarial bands”, “validation engine”, or “bias controller”, they are pointing back to these research‑oriented chapters.</p>
  <p>Finally, the engine leans on a specific set of implementation technologies which are also documented in an explanatory rather than purely reference‑style manner. The chapters on <a href="dimensions.html">Empirical Space</a>, <a href="ontology_dims.html">Ontology Dimensions</a>, and <a href="axiology_dims.html">Axiology Dimensions</a> describe how the global vector space is partitioned into interpretable regions, how new empirical dimensions can be discovered safely, and how those regions stay stable across runs. The <a href="architecture.html">Architecture</a> chapter tells the story of how modules like VectorSpace, MathEngine, BoundedDiamond, ConceptStore, Retriever, and Reasoner collaborate, while <a href="ingestion.html">Ingestion</a> and <a href="learning.html">Learning</a> explain the data pipeline from text to vectors and from raw observations to evolving concepts. Taken together, these texts act as the “Research & Technologies” wiki that more task‑specific pages link back to whenever they use specialised terminology.</p>

  <h2>Vision and Design Principles</h2>
  <p>The engine is built to be the opposite of a black box. Determinism replaces sampling; geometry replaces opaque weights; facts and values live on separate axes; conflicting theories can coexist and be compared; explanations come “for free” because every decision is a distance check with named dimensions. This section collects the high‑level philosophy behind those choices and points to the deeper wiki chapters when needed. If you are new to the project, reading these essays in order will give you a mental model for why the system looks the way it does.</p>
  <p>The narrative begins with <a href="conceptual_spaces.html">Conceptual Spaces</a>, which introduces the idea that concepts are regions, facts are points, and reasoning is movement within a geometric space. From there, the <a href="reasoning.html">Reasoning</a> chapter shows how deduction, induction, abduction, counterfactual reasoning, and temporal or deontic logic can all be phrased as questions about whether a point lies inside or outside various bounded diamonds. The <a href="bias.html">Bias & Values</a> chapter explains how facts and value judgements occupy different partitions of the space, while <a href="explainability.html">Explainability</a> shows how every decision can be retold as a human‑readable proof that cites distances, masks, and active theory layers instead of probability scores or opaque activations. Throughout these chapters there are references back to <a href="algorithms.html">Algorithms & Acronyms</a> whenever a concrete technique such as LSH or vector permutation first appears.</p>

  <h2>Why Use It (Pragmatics)</h2>
  <p>AGISystem2 shines where rules matter, conflicts must be explicit, and reproducibility is non‑negotiable. Typical application domains include regulatory compliance where multiple regimes such as GDPR and HIPAA must be compared, safety checks in pipelines that mix symbolic rules and generative models, expert systems in which exceptions and counterexamples are common, narrative consistency for complex agents, and any scenario where you want a deterministic anchor next to a probabilistic model. The <a href="pragmatics.html">Pragmatics</a> chapter describes these use cases in narrative form, connecting each scenario back to the geometric and architectural concepts explained in the research‑oriented wiki. The chapters on <a href="expert_mode.html">Expert System Mode</a> and <a href="rag.html">RAG</a> then specialise this discussion: Expert System Mode focuses on building layered rule systems with explicit overrides, while the RAG chapter shows how to pair AGISystem2 with large language models so that generation is constrained and checked by the conceptual space.</p>

  <h2>API & Practical Considerations</h2>
  <p>To drive the engine in practice, you work with a constrained grammar, configuration profiles, and a small but expressive API surface. The <a href="api.html">API</a> chapter explains how to obtain an EngineAPI instance, how to open an agentic session, and what guarantees you get in terms of provenance and reproducibility. Whenever that chapter mentions elements such as the Reasoner, Retriever, or ValidationEngine, you can cross‑reference the <a href="architecture.html">Architecture</a> and <a href="reasoning.html">Reasoning</a> pages for deeper background on how those components behave internally. The <a href="grammar.html">Grammar</a> chapter then walks through the sentence patterns the system accepts, how natural language is normalised into those patterns, and how expressions such as counterfactuals or deontic statements are encoded; it regularly points back to <a href="conceptual_spaces.html">Conceptual Spaces</a> and <a href="algorithms.html">Algorithms & Acronyms</a> so that the underlying geometry is never mysterious.</p>
  <p>Engine behaviour is heavily influenced by configuration, which is why <a href="config.html">Configuration</a> and the dimension‑related chapters are written as narrative guides rather than terse parameter lists. When you choose a profile, set the total dimensionality, or adjust the number of LSH bands, you are effectively choosing a trade‑off between precision, recall, and resource usage. The documentation explains these trade‑offs with concrete, implementation‑level examples: for instance, what happens to adversarial bands when you shrink radii, or how value‑sensitive dimensions affect retrieval in deontic reasoning. The pages on <a href="relations.html">Relations</a>, <a href="ontology_dims.html">Ontology Dimensions</a>, <a href="axiology_dims.html">Axiology Dimensions</a>, <a href="dimensions.html">Empirical Space</a>, <a href="ingestion.html">Ingestion</a>, and <a href="config.html">Configuration</a> form a connected reference that you can read linearly or dip into when a particular technical term comes up elsewhere.</p>

  <h2>Supporting Chapters</h2>
  <p>The remaining chapters provide depth and context for readers who want to understand the system as an evolving research project rather than a frozen product. The <a href="architecture.html">Architecture</a> chapter tells the story of the main modules and their responsibilities, from VectorSpace and MathEngine up to Reasoner, BiasController, and Storage. The <a href="learning.html">Learning</a> chapter explains how concepts change over time through clustering, splitting, and merging of bounded diamonds, and how temporal memory interacts with long‑term storage. The <a href="limits.html">Limits</a> chapter is explicit about what the engine does not try to do, how geometric representations can fail, and which mitigation strategies are built in, while the <a href="roadmap.html">Roadmap</a> chapter sketches future research directions such as richer temporal logics, better integration with external knowledge bases, and tooling for interactive proof exploration.</p>
  <p>Each chapter in this documentation set is intentionally longer than a short note or checklist so that non‑experts in machine learning can still build an accurate mental model of the system. You can read the pages in the suggested order, or you can treat the “Research & Technologies” section above as an index into the wiki‑style explanations of individual concepts. If you are new, begin with Vision and Reasoning. If you are integrating the engine into an application, focus on API, Grammar, Relations, Configuration, and the ingestion pipeline. If you are auditing, spend more time with Explainability, Bias & Values, Limits, and the architecture overview, using the cross‑references to navigate between theory and implementation.</p>

  <p>For concise definitions of the main philosophical and technical notions used across these chapters, including links to external references and dedicated concept pages, you can consult the <a href="wiki/quick_wiki.html">Quick Wiki of concepts</a>.</p>

      function openModal(id) {
        var modal = document.getElementById('concept-modal-' + id);
        if (!modal) return;
        modal.classList.add('is-visible');
        backdrop.classList.add('is-visible');
      }

      function closeModal(id) {
        var modal = document.getElementById('concept-modal-' + id);
        if (!modal) return;
        modal.classList.remove('is-visible');
        if (!document.querySelector('.concept-modal.is-visible')) {
          backdrop.classList.remove('is-visible');
        }
      }

      document.addEventListener('click', function (evt) {
        var openTarget = evt.target.closest('.concept-link-button');
        if (openTarget && openTarget.dataset.concept) {
          evt.preventDefault();
          openModal(openTarget.dataset.concept);
          return;
        }
        var closeTarget = evt.target.closest('.concept-modal-close');
        if (closeTarget && closeTarget.dataset.conceptClose) {
          evt.preventDefault();
          closeModal(closeTarget.dataset.conceptClose);
          return;
        }
        if (evt.target === backdrop) {
          var open = document.querySelector('.concept-modal.is-visible');
          if (open && open.id.indexOf('concept-modal-') === 0) {
            var id = open.id.replace('concept-modal-', '');
            closeModal(id);
          }
        }
      });

      document.addEventListener('keydown', function (evt) {
        if (evt.key === 'Escape') {
          var open = document.querySelector('.concept-modal.is-visible');
          if (open && open.id.indexOf('concept-modal-') === 0) {
            var id = open.id.replace('concept-modal-', '');
            closeModal(id);
          }
        }
      });
    })();
  </script>

  <div class="footer-nav">
    <p>This documentation is part of the research work carried out by <a href="https://www.axiologic.net" target="_blank" rel="noopener noreferrer">Axiologic Research</a> within the <a href="https://www.achilles-project.eu/" target="_blank" rel="noopener noreferrer">ACHILLES</a> project on trustworthy AI. It is written as an experiment in close collaboration between human researchers and AI tools, using specification‑driven development to design and explain technologies for trustworthy AI and future AGI in a reproducible way.</p>
  </div>
  </div>
 </body>
 </html>

