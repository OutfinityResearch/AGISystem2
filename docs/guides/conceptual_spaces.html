<!doctype html>
<html>
<head>
  <meta charset="utf-8">
  <title>Conceptual Spaces</title>
  <link rel="stylesheet" href="../reference/style.css">
</head>
<body>
  <div class="page">
  <div class="nav-header">
    <h1>Conceptual Spaces: From Theory to Engineering</h1>
    <small>
      <a href="../index.html">Home</a> ·
      <a href="conceptual_spaces.html">Theory</a> ·
      <a href="../guides/architecture.html">Architecture</a> ·
      <a href="../api/index.html">APIs</a> ·
      <a href="../syntax/index.html">Syntax</a> ·
      <a href="../usage-cli/index.html">CLI</a> ·
      <a href="../wiki/index.html">Wiki</a> ·
      <a href="../specs/matrix.html">Specs</a>
    </small>
    <div class="sub-nav">
      <strong>Theory Topics:</strong>
      <a href="conceptual_spaces.html">Conceptual Spaces</a> ·
      <a href="reasoning.html">Reasoning</a> ·
      <a href="bias.html">Bias & Values</a> ·
      <a href="explainability.html">Explainability</a> ·
      <a href="learning.html">Learning</a> ·
      <a href="limits.html">Limits</a> ·
      <a href="roadmap.html">Roadmap</a>
    </div>
  </div>
  <p>Conceptual spaces start from a simple but powerful idea: meaning can be treated as geometry. Instead of thinking about knowledge only as symbols and rules, or only as weights in a neural network, we imagine a space with many dimensions. Each dimension corresponds to some quality that the system can measure or care about, and every concrete statement becomes a point in that space. Concepts are then regions that group together many related points. AGISystem2 adopts this view and turns it into an explicit, inspectable data structure built from high-dimensional int8 vectors, bounded diamonds, and relevance masks. Throughout the rest of the documentation, when you see terms like “concept”, “region”, or “bounded diamond”, they refer back to the picture developed in this chapter.</p>

  <h2>Facts as Points, Concepts as Regions</h2>
  <p>When text comes into the system it is first normalised and reduced to a constrained grammar. A simple statement such as "Dog IS_A Animal" or "Water HAS_PROPERTY boiling_point = 100" is turned into a small tree of subject, relation, and object. The encoder then assigns each part a vector, permutes those vectors according to the roles they play, and adds them together using saturated arithmetic. The result is a single high-dimensional int8 vector that represents that fact. In geometric terms this vector is a point in the global conceptual space. That point can later be looked up through the retrieval engine, combined with other points during learning, or used as a query to ask whether a concept applies.</p>
  <p>A concept does not live at a single point. Over time, many facts accumulate that refer to the same idea, and those facts trace out a cloud of points in the space. Rather than storing every point separately, AGISystem2 summarises that cloud as one or more bounded diamonds. A bounded diamond is the intersection of an axis-aligned box, an L1 ball centred near the mean of the examples, and a relevance mask that states which dimensions matter for this concept. If the same word is used in several very different senses, the system can maintain several diamonds for it, capturing polysemy explicitly. This view of concepts as regions built from observed points is what enables the reasoning procedures described in the Reasoning chapter to be implemented as geometric checks.</p>

  <div class="diagram">
    <svg viewBox="0 0 260 160" role="img" aria-label="Schematic conceptual space with ontology and axiology axes and a bounded diamond region">
      <defs>
        <marker id="arrow" markerWidth="6" markerHeight="6" refX="5" refY="3" orient="auto" markerUnits="strokeWidth">
          <path d="M0,0 L6,3 L0,6 z" fill="#0f4c81" />
        </marker>
      </defs>
      <line x1="40" y1="130" x2="220" y2="130" stroke="#0f4c81" stroke-width="1.2" marker-end="url(#arrow)" />
      <line x1="40" y1="130" x2="40" y2="20" stroke="#0f4c81" stroke-width="1.2" marker-end="url(#arrow)" />
      <text x="222" y="135" font-size="9" fill="#0f4c81">Ontology axes</text>
      <text x="18" y="22" font-size="9" fill="#0f4c81" transform="rotate(-90 18 22)">Axiology axes</text>
      <rect x="95" y="55" width="90" height="55" fill="#e1ecf7" stroke="#0f4c81" stroke-width="1" />
      <polygon points="140,50 200,82 140,140 80,108" fill="none" stroke="#0f4c81" stroke-dasharray="4 3" stroke-width="1" />
      <circle cx="140" cy="96" r="4" fill="#0f4c81" />
      <text x="144" y="90" font-size="8" fill="#0f4c81">centre</text>
      <text x="100" y="68" font-size="8" fill="#0f4c81">box bounds</text>
      <text x="148" y="132" font-size="8" fill="#0f4c81">L1 radius</text>
    </svg>
    <p class="diagram-caption">This schematic diagram shows a tiny slice of the conceptual space with one horizontal direction standing in for many ontology dimensions and the vertical direction standing in for axiology dimensions. The blue rectangle illustrates the per-dimension bounds that constrain a concept, while the dashed diamond shows how an L1 radius trims away the far corners of that box. The point at the centre is a typical encoded fact, and membership tests ask whether such points fall inside the intersection of box and diamond under the currently active relevance mask.</p>
  </div>

  <h2>Why Geometry Instead of Pure Symbols?</h2>
  <p>Traditional symbolic systems represent knowledge as discrete predicates and rules. They are precise but brittle: a single missing rule can cause an inference to fail, and adding new rules can unintentionally create contradictions. Purely neural approaches, in contrast, hide their state in floating point weights and activations that are difficult to interpret and audit. Conceptual spaces offer a middle road. By mapping statements into a geometric space with named or at least well-partitioned dimensions, AGISystem2 can compute with vectors while still offering human-scale interpretations. A point belongs to a concept when it lies inside its region. Two concepts contradict each other when their regions do not intersect under the current theory stack. Exceptions and counterexamples appear as points that fall near the boundary or inside one region but not another.</p>
  <p>Geometry also plays well with incremental learning. When new facts arrive they shift the centre of a region, widen its bounds, or cause the system to split a diamond into several clusters. These operations correspond to simple vector updates and min/max adjustments rather than global retraining. Because dimensions are fixed and arithmetic is done in int8, the cost of these updates is predictable and easy to reason about. Other documents describe how components like <code>BoundedDiamond</code>, <code>MathEngine</code>, and <code>ConceptStore</code> carry out these operations in detail, but the geometric picture stays the same: learning means sculpting regions so that they better fit the observed points.</p>

  <h2>Why Bounded Diamonds and Not Simple Boxes?</h2>
  <p>In a low-dimensional space a box is easy to visualise, but in hundreds or thousands of dimensions a pure axis-aligned box becomes extremely generous: most of its volume lies in far-off corners that no real observation will ever reach. An L1 ball, on the other hand, has a smoother boundary but does not respect known hard limits per dimension. By intersecting a box with an L1 ball we obtain a diamond-shaped region that is strict where it must be and forgiving where it should be. The box imposes explicit min and max bounds per dimension, such as "temperature must be between 0 and 100" or "velocity cannot be negative". The L1 ball trims away unrealistic corners in high dimensions so that distance-based reasoning remains meaningful and robust.</p>
  <p>The relevance mask is the third ingredient. Many dimensions exist in the global space that are irrelevant for a particular concept. For example, the legal liability dimensions in the ontology catalogue are not useful for reasoning about the colour of an apple. The relevance mask records, for each dimension, whether it participates in the definition of this concept. During distance computations the MathEngine will ignore dimensions whose mask bits are cleared. This keeps both computation and explanations focused on the axes that actually matter. When later chapters talk about "sparsity as attention" or "relevance-driven proofs", they are referring directly to this use of masks.</p>

  <h2>Partitions of Meaning: Ontology, Axiology, Empirical Tail</h2>
  <p>The conceptual space used by AGISystem2 is not a formless cloud of numbers. Its coordinate system is deliberately partitioned to reflect different kinds of meaning. Ontology dimensions, numbered from 0 to 255, carry factual and structural information about the world: physical properties, temporal attributes, agency, process characteristics, risk markers, and more, as described in the dimension catalogue specification. Axiology dimensions, from 256 to 383, encode values, norms, and preferences: which actions are permitted, which are obligatory, which outcomes are considered harmful or beneficial. Everything above 383 is reserved for empirical or latent dimensions discovered during ingestion and learning.</p>
  <p>This partitioning supports the strict separation between facts and values that is central to the Bias &amp; Values chapter. When a theory layer encodes that a certain action is forbidden in one jurisdiction but permitted in another, it does so by adjusting only axiology dimensions while leaving ontology untouched. The BiasController can then apply modes such as a veil-of-ignorance by masking some axiology axes or sensitive ontological axes before a reasoning step. As a result, the same factual region can be evaluated under different value systems without corrupting the underlying concept. Narrative examples elsewhere in the documentation show how changing value layers changes only the deontic outcome bands, not the underlying factual membership.</p>

  <h2>High-Dimensional Design Choices</h2>
  <p>Choosing high-dimensional int8 vectors is an engineering decision informed by research on hyperdimensional computing. With hundreds or thousands of dimensions, most randomly chosen vectors are nearly orthogonal. This property allows the engine to use superposition: adding vectors corresponding to several observations reinforces consistent features while letting noise cancel out statistically. Using int8 instead of floating point keeps memory usage and cache behaviour predictable, which matters in long-running or embedded deployments. The MathEngine implements saturated addition so that even long histories of updates cannot overflow the numeric range.</p>
  <p>Structure such as roles, time steps, and causal directions is encoded through permutations rather than by adding extra dimensions. The RelationPermuter module maintains a deterministic permutation table for each relation, as well as inverse permutations when needed. When the encoder binds a child phrase to its parent via a relation, it permutes the child’s vector according to that relation and then adds it to the parent. This keeps the total dimensionality fixed while still encoding "who did what to whom and when". Retrieval uses locality-sensitive hashing to quickly find candidate diamonds near a query point, and then the MathEngine computes exact masked L1 distances. Because all of these components use seeded randomness and respect the global dimension configuration, two runs with the same inputs and seeds will always produce the same vectors and thus the same reasoning outcomes.</p>

  <div class="diagram">
    <svg viewBox="0 0 320 150" role="img" aria-label="Dimensional layout and concept, fact, context elements in the conceptual space">
      <rect x="20" y="30" width="90" height="26" rx="4" fill="#e1ecf7" stroke="#0f4c81" stroke-width="1" />
      <text x="30" y="46" font-size="8" fill="#0f4c81">Ontology 0–255</text>
      <rect x="120" y="30" width="90" height="26" rx="4" fill="#fbe9e9" stroke="#b03a48" stroke-width="1" />
      <text x="130" y="46" font-size="8" fill="#b03a48">Axiology 256–383</text>
      <rect x="220" y="30" width="80" height="26" rx="4" fill="#f3f3f3" stroke="#b0b6c4" stroke-width="1" />
      <text x="228" y="46" font-size="8" fill="#4a5670">Empirical 384+</text>
      <rect x="40" y="80" width="70" height="26" rx="4" fill="#ffffff" stroke="#0f4c81" stroke-width="1" />
      <text x="51" y="96" font-size="8" fill="#0f4c81">Concept</text>
      <rect x="130" y="80" width="60" height="26" rx="4" fill="#ffffff" stroke="#0f4c81" stroke-width="1" />
      <text x="146" y="96" font-size="8" fill="#0f4c81">Fact</text>
      <rect x="210" y="80" width="80" height="26" rx="4" fill="#ffffff" stroke="#0f4c81" stroke-width="1" />
      <text x="223" y="96" font-size="8" fill="#0f4c81">Context stack</text>
      <line x1="70" y1="56" x2="70" y2="80" stroke="#0f4c81" stroke-width="1" />
      <line x1="160" y1="56" x2="160" y2="80" stroke="#0f4c81" stroke-width="1" />
      <line x1="250" y1="56" x2="250" y2="80" stroke="#0f4c81" stroke-width="1" />
    </svg>
    <p class="diagram-caption">The dimensional layout divides the global vector space into ontology, axiology and empirical ranges. Concepts are unions of diamonds that live across these dimensions, individual facts are single points encoded from normalised sentences, and context is represented as a stack of theory layers that adjust how those concepts are seen at runtime. This diagram replaces the ASCII sketch with a compact visual summary of those relationships.</p>
  </div>


  <h2>Relation to OWL and the Semantic Web</h2>
  <p>AGISystem2 sits close to, but not inside, the tradition of OWL and the Semantic Web. OWL ontologies, RDF graphs, and SPARQL queries offer a rich, logic-based framework where classes, properties, and individuals are described by axioms and reasoners derive consequences through subsumption and satisfiability checks. This ecosystem brings well-understood formalisms, tooling for schema design, and interoperability via shared vocabularies. The geometric approach described in this chapter borrows the idea of explicit ontologies, named relations, and machine-readable structure, but it changes the representation layer: instead of describing the world in logical formulas over triples, it anchors these triples in a high-dimensional conceptual space. In other words, AGISystem2 treats OWL-like statements as a surface language that is compiled into regions and points rather than as the final internal representation.</p>
  <p>Where OWL reasoners operate by applying inference rules and checking model-theoretic semantics, AGISystem2 operates by measuring distances and testing membership in bounded diamonds. Subclass relations echo <code>IS_A</code> hierarchies, object properties resemble relations like <code>LOCATED_IN</code> or <code>PART_OF</code>, and data properties correspond to axes in the conceptual space. However, instead of working with rigid class expressions such as <code>Human and (hasAge some integer)</code>, the engine treats “Human” as a region in the space, “hasAge” as a contribution along specific dimensions, and individual facts as points. Non-monotonic behaviour that is difficult to express in standard OWL, such as default rules with exceptions, is implemented through theory layers that overlay and override parts of that space without rewriting base axioms.</p>
  <p>Another difference lies in how AGISystem2 handles vagueness and graded truth. The Semantic Web stack is largely bivalent: a triple is either entailed or not under an interpretation. Extensions exist for fuzzy or probabilistic ontologies, but they are not mainstream practice. In this engine, membership in a concept is always a matter of distance and bands: points can be clearly inside, clearly outside, or in a grey zone. This allows the system to mirror the imprecise boundaries that appear in natural language and empirical data, while still offering deterministic decisions for applications that need them. Instead of asking whether an individual satisfies a class description exactly, AGISystem2 asks how close the encoded fact lies to the centre of the conceptual region and how that distance compares to sceptic and optimist radii.</p>
  <p>Despite these differences, the engine can interoperate with Semantic Web artefacts at the interface. An OWL or RDF vocabulary can serve as the source of names for concepts and relations; basic subsumption hierarchies can be imported and treated as initial <code>IS_A</code> chains; deontic annotations can inform value dimensions and theory layers. What the system does not do is execute OWL inference rules directly or support the full expressivity of OWL class constructors in its core. Instead, it offers a geometric substrate that can host ontologies imported from OWL, enriched with empirical learning and non-monotonic layers. When you think in terms of OWL, you can imagine AGISystem2 as a different model of the same vocabulary: one where meanings live as shapes in a conceptual space rather than only as nodes in a graph.</p>

  <h2>Links to the Literature and to the Codebase</h2>
  <p>The conceptual spaces idea originates in work by Peter Gärdenfors and others who argued for a geometric middle layer between symbols and subsymbolic vectors. Hyperdimensional computing, as developed by Pentti Kanerva and subsequent researchers, shows how to represent complex structures using high-dimensional vectors, permutations, and binding operations. From the perspective of dimensionality reduction, results like the Johnson–Lindenstrauss lemma give intuition for why distances can remain meaningful in high dimensions. AGISystem2 borrows from all of these lines of work but grounds them in deterministic, auditable Node.js components; the shape of the space is captured conceptually in the descriptions of ontology and axiology dimensions and is instantiated at runtime from configuration and initial data files.</p>
  <p>If you want to see how the geometric ideas map to concrete modules, you can read this chapter together with the implementation-oriented guides and references. The modules that handle the raw geometry are introduced in the <a href="../guides/architecture.html">Architecture</a> chapter and described in more detail in the reference pages: <a href="../theory/dimensions.html">Empirical Space</a> shows how the global vector is partitioned, while <a href="../theory/ontology_dims.html">Ontology Dimensions</a> and <a href="../theory/axiology_dims.html">Axiology Dimensions</a> spell out the fixed semantic axes. On top of that, the <code>VectorSpace</code> and <code>MathEngine</code> components implement buffer allocation, clamped arithmetic, masked L1 distance, permutations, and temporal rotations; the <code>BoundedDiamond</code> class implements the box-plus-diamond region for a concept; the <code>ConceptStore</code> manages unions of diamonds and raw fact triples; and the <code>TheoryStack</code> captures context overlays that turn a static space into a layered, meta-rational one. The Retriever, whose role is explained in the <a href="../theory/relations.html">Relations</a> <a href="../theory/relations.html">Relations</a> pages, uses locality-sensitive hashing to find candidate regions efficiently before handing distance checks back to the MathEngine.</p>
  <p>When reading other documentation pages you can treat this chapter as the background reference for any mention of regions, masks, diamonds, or partitions. The <a href="../guides/reasoning.html">Reasoning</a> chapter shows how membership in a diamond becomes a deduction step, how inverse permutations and translations implement abduction and analogy, and how theory layers enable counterfactuals. The <a href="../guides/bias.html">Bias &amp; Values</a> chapter relies on the ontological and axiological partitions described here to explain how facts and value judgements are kept separate and how different value systems can be loaded as theory layers. The <a href="../guides/explainability.html">Explainability</a> chapter assumes that regions and masks are explicit objects that can be cited in proofs and audit trails. For a system-level picture of how all modules interact—from ingestion, through conceptual space, to answers—you can follow the diagram and narrative in the <a href="../guides/architecture.html">Architecture</a> chapter; that page shows how conceptual spaces fit into the larger design, while this one focuses on the semantic geometry itself.</p>

  <div class="footer-nav">
    <a href="../index.html">Back to index</a>
    <a href="../wiki/index.html">Quick Wiki</a>
  </div>
  </div>
  <script src="../reference/nav2.js"></script>
</body>
</html>
