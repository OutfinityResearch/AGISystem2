<!doctype html>
<html>
<head>
  <meta charset="utf-8">
  <title>Veil of Ignorance</title>
  <link rel="stylesheet" href="../reference/style.css">
</head>
<body>
  <div class="page">
  <div class="nav-header">
    <h1>Veil of Ignorance</h1>
    <small></small>
    <div class="sub-nav">
      <strong>Wiki Topics:</strong>
      <a href="index.html">Concepts Overview</a> · <a href="abduction.html">Abduction</a> · <a href="analogy.html">Analogy</a> · <a href="axiology.html">Axiology</a> · <a href="bias.html">Bias</a> · <a href="conceptual_spaces.html">Conceptual Spaces</a> · <a href="counterfactual.html">Counterfactuals</a> · <a href="deontic_logic.html">Deontic Logic</a> · <a href="expert_system.html">Expert Systems</a> · <a href="hyperdimensional_computing.html">Hyperdimensional Computing</a> · <a href="narrative_consistency.html">Narrative Consistency</a> · <a href="non_monotonic_logic.html">Non-Monotonic Logic</a> · <a href="ontology.html">Ontology</a> · <a href="pragmatics.html">Pragmatics</a> · <a href="symbol_grounding.html">Symbol Grounding</a> · <a href="trustworthy_ai.html">Trustworthy AI</a> · <a href="veil_of_ignorance.html">Veil of Ignorance</a>
    </div>
  </div>
  <article>
    <div class="philosophical-header">
      <h2>Rawls’ Veil of Ignorance</h2>
      <p>The “veil of ignorance” is a thought experiment introduced by philosopher John Rawls. It imagines a group of rational agents tasked with designing the basic rules of a society, but forced to do so without knowing their own position in that society: they do not know their class, gender, health, or talents. Behind the veil, they must choose principles that they would accept no matter where they end up.</p>
      <p>This device is meant to operationalise impartiality. If you do not know whether you will be rich or poor, healthy or sick, majority or minority, you are incentivised to design fair rules—ones that protect the worst-off as well as the best-off. The veil of ignorance thus connects moral reasoning with an information constraint.</p>
    </div>

    <div class="academic-analysis">
      <h2>From Philosophy to Decision Procedures</h2>
      <p>In decision theory and AI ethics, the veil of ignorance inspires procedures that remove or mask information about particular individuals before evaluating outcomes. Rather than attempting to encode all ethical theories directly, a system can simulate “ignorance” about protected attributes and ask whether a decision would still be acceptable under that constraint.</p>
      <p>This perspective is especially relevant for automated decision systems in hiring, lending, healthcare, or criminal justice, where knowledge of certain attributes (such as race or gender) should not influence outcomes.</p>
    </div>

    <div class="academic-analysis">
      <h2>Veil of Ignorance in AGISystem2</h2>
      <p>AGISystem2 implements veil-of-ignorance style reasoning through masking in the conceptual space. The <code>BiasController</code> can activate modes in which selected dimensions—those corresponding to protected attributes or sensitive value-laden axes—are zeroed out or ignored during distance computations and decision-making.</p>
      <p>When such a mode is active, the Reasoner evaluates queries “as if” it did not know where individuals sit along those dimensions. This does not erase the information from storage, but it removes its influence from the specific reasoning step, and records the use of the mask in provenance metadata.</p>
      <p>Bias audit suites then compare outcomes with and without the veil: if decisions change dramatically when protected dimensions are masked, this is a signal that the underlying theory or data may contain problematic dependencies.</p>
    </div>

    <div class="philosophical-implications">
      <h2>Philosophical and Practical Implications</h2>
      <p>Using veil-of-ignorance style masks does not solve all fairness questions, but it provides a concrete, inspectable mechanism for exploring them. It shifts the conversation from vague assurances of neutrality to explicit statements: “this decision was computed under a fairness mode that masked dimensions X, Y, Z”.</p>
      <p>Practically, this allows regulators, auditors, and domain experts to test whether certain outcomes depend on information that should not matter, and to refine theories or policies accordingly.</p>
    </div>

    <div class="academic-references">
      <h2>Academic References</h2>
      <p>The veil of ignorance is central to Rawls’ theory of justice and has been widely discussed in political philosophy and ethics. In AI and algorithmic fairness, related ideas appear in discussions of counterfactual fairness, demographic parity, and fairness through unawareness.</p>
      <p>For background, see <a href="https://en.wikipedia.org/wiki/Veil_of_ignorance" target="_blank" rel="noopener noreferrer">the literature on the veil of ignorance</a>.</p>
    </div>

    <div class="technical-specifications">
      <h2>Technical Implementation References</h2>
      <p>For detailed technical specifications of veil-of-ignorance style masking in AGISystem2, consult the following design and test specifications (referenced by ID):</p>
      <ul>
        <li>DS[/reason/bias_control.js] — implements bias modes, including veil-like masking over selected dimensions.</li>
        <li>DS[/knowledge/dimensions] — keeps protected axes explicit so that they can be masked and audited.</li>
        <li>DS[/tests/bias_audit/runSuite] — provides automated scenarios for checking decisions under different masking modes.</li>
      </ul>
    </div>
  </article>
  <div class="footer-nav">
    <a href="../index.html">Back to index</a>
  </div>
  </div>
  <script src="../reference/nav2.js"></script>
</body>
</html>
