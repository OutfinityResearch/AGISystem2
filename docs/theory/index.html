<!doctype html>
<html>
<head>
  <meta charset="utf-8">
  <title>Theory - AGISystem2</title>
  <link rel="stylesheet" href="../reference/style.css">
</head>
<body>
  <div class="page">
  <div class="nav-header">
    <h1>Theoretical Foundation</h1>
    <small>
      <a href="../index.html">Home</a> &middot;
      <a href="../architecture/index.html">Architecture</a> &middot;
      <a href="../reasoning/index.html">Reasoning</a> &middot;
      <a href="index.html"><strong>Theory</strong></a> &middot;
      <a href="../syntax/index.html">Syntax</a> &middot;
      <a href="../api/index.html">APIs</a> &middot;
      <a href="../wiki/index.html">Wiki</a> &middot;
      <a href="../specs/matrix.html">Specs</a> &middot;
      <a href="../research/index.html">Research</a>
    </small>
    <small>Hyperdimensional Computing for neuro-symbolic AI</small>
  </div>

  <div class="section-intro">
    <p>AGISystem2 is built on <strong>Hyperdimensional Computing (HDC)</strong>, a computational paradigm that represents information as high-dimensional vectors. This foundation enables deterministic, explainable reasoning with mathematical guarantees.</p>
  </div>

  <h2>Why Hyperdimensional Computing?</h2>

  <div class="section-grid">
    <div class="section-card">
      <h3>Determinism</h3>
      <p>Unlike probabilistic neural networks, HDC operations are fully deterministic. The same input always produces the same output, enabling perfect reproducibility and debugging.</p>
    </div>

    <div class="section-card">
      <h3>Compositionality</h3>
      <p>Complex structures can be built from simple parts using only two operations (Bind and Bundle). This enables systematic construction and deconstruction of knowledge.</p>
    </div>

    <div class="section-card">
      <h3>Noise Tolerance</h3>
      <p>High-dimensional representations are naturally robust to noise and errors. Small perturbations don't significantly affect similarity comparisons.</p>
    </div>

    <div class="section-card">
      <h3>Efficiency</h3>
      <p>Core operations are extremely fast on modern hardware. The mathematical structure allows for hardware-friendly implementations.</p>
    </div>
  </div>

  <h2>Core Concepts</h2>

  <h3>The Hypervector</h3>

  <p>The fundamental data structure is a <strong>hypervector</strong> - a high-dimensional representation where each concept occupies a unique region in the vector space.</p>

  <div class="alert alert-info">
    <strong>Key Insight:</strong> In high-dimensional spaces, randomly generated vectors are almost orthogonal to each other. This "quasi-orthogonality" property means any new concept gets a representation that doesn't interfere with existing ones.
  </div>

  <h3>The Three Core Operations</h3>

  <table>
    <tr>
      <th>Operation</th>
      <th>Purpose</th>
      <th>Mathematical Property</th>
    </tr>
    <tr>
      <td><strong>BIND</strong></td>
      <td>Create associations between concepts</td>
      <td>Self-inverse: (A BIND B) BIND B = A</td>
    </tr>
    <tr>
      <td><strong>BUNDLE</strong></td>
      <td>Combine multiple vectors into one</td>
      <td>Result is similar to all inputs</td>
    </tr>
    <tr>
      <td><strong>SIMILARITY</strong></td>
      <td>Measure relatedness</td>
      <td>Range [0, 1], 0.5 = unrelated</td>
    </tr>
  </table>

  <h3>Position Vectors</h3>

  <p>Because BIND is commutative, we need a mechanism to distinguish argument positions. Position vectors (Pos1, Pos2, ..., Pos20) solve this:</p>

  <pre><code>// Without positions: loves(John, Mary) = loves(Mary, John) (WRONG!)
// With positions:
fact = Loves BIND (Pos1 BIND John) BIND (Pos2 BIND Mary)  // loves(John, Mary)
fact = Loves BIND (Pos1 BIND Mary) BIND (Pos2 BIND John)  // loves(Mary, John) - DIFFERENT!</code></pre>

  <h3>The Reasoning Equation</h3>

  <p>All queries reduce to this fundamental principle:</p>

  <div class="alert alert-info">
    <strong>Answer = Knowledge BIND Query<sup>-1</sup></strong>
    <p>Since BIND is self-inverse, "unbinding" the known parts of a query from the knowledge base reveals the unknown parts.</p>
  </div>

  <h2>HDC Strategies</h2>

  <p>AGISystem2 implements multiple HDC strategies, each with different internal representations while maintaining the same mathematical contract:</p>

  <div class="section-grid">
    <div class="section-card">
      <h3>Dense-Binary</h3>
      <p>Classic HDC with fixed-length binary vectors. Uses XOR for binding and majority vote for bundling.</p>
      <p><a href="strategies/dense-binary.html">Full Documentation &rarr;</a></p>
    </div>

    <div class="section-card">
      <h3>Sparse Polynomial (SPHDC)</h3>
      <p>Set-based HDC with k integer exponents. Uses Cartesian XOR for binding and Jaccard index for similarity.</p>
      <p><a href="strategies/sparse-polynomial.html">Full Documentation &rarr;</a></p>
    </div>

    <div class="section-card" style="background: linear-gradient(135deg, #fff3e022 0%, #ffe0b222 100%);">
      <h3>Metric-Affine</h3>
      <p>Compact 32-byte vectors over Z₂₅₆. Uses XOR binding with L₁ similarity and arithmetic mean bundling. Fuzzy-Boolean Hyper-Lattice.</p>
      <p><a href="strategies/metric-affine.html">Full Documentation &rarr;</a></p>
    </div>
  </div>

  <h2>HRR Comparison: Original Contributions</h2>

  <p>AGISystem2 implements three HDC strategies, two of which are <strong>original contributions</strong> not found in existing literature. How do they relate to Tony Plate's Holographic Reduced Representations (HRR)?</p>

  <div class="section-grid">
    <div class="section-card">
      <h3><a href="hrr-comparison.html">HRR vs. Our Strategies</a></h3>
      <p>Detailed analysis of Dense-Binary (standard), Sparse Polynomial (novel), and Metric-Affine (novel) against classic HRR.</p>
    </div>

    <div class="section-card" style="background: linear-gradient(135deg, #f3e5f522 0%, #ce93d822 100%);">
      <h3>Sparse Polynomial (SPHDC)</h3>
      <p><strong>ORIGINAL:</strong> Set-based HDC with Cartesian XOR binding and Min-Hash sparsification. NOT HRR - a novel paradigm.</p>
    </div>

    <div class="section-card" style="background: linear-gradient(135deg, #fff3e022 0%, #ffe0b222 100%);">
      <h3>Metric-Affine</h3>
      <p><strong>ORIGINAL:</strong> Fuzzy-Boolean hybrid combining XOR binding with continuous bundling. HRR-inspired but novel.</p>
    </div>
  </div>

  <div class="alert alert-info">
    <strong>Summary:</strong> Dense-Binary is standard VSA/HDC. Sparse Polynomial and Metric-Affine are original contributions developed for AGISystem2, each introducing novel mathematical foundations for hyperdimensional reasoning.
  </div>

  <h2>Trustworthy AI</h2>

  <p>HDC's deterministic, explainable nature makes it ideal for building <strong>trustworthy AI systems</strong>&mdash;AI that can be verified, audited, and understood.</p>

  <div class="section-grid">
    <div class="section-card" style="background: linear-gradient(135deg, #4caf5022 0%, #8bc34a22 100%);">
      <h3><a href="trustworthy-ai/index.html">Trustworthy AI Overview</a></h3>
      <p>How HDC enables verifiable, explainable, auditable AI. Common patterns and approaches.</p>
    </div>

    <div class="section-card">
      <h3><a href="trustworthy-ai/agent-planning.html">Agent Planning</a></h3>
      <p>Formal tool semantics, plan verification before execution, failure diagnosis.</p>
    </div>

    <div class="section-card">
      <h3><a href="trustworthy-ai/compliance.html">Compliance & Verification</a></h3>
      <p>Real-time regulatory checking, automatic audit trails, remediation guidance.</p>
    </div>

    <div class="section-card">
      <h3><a href="trustworthy-ai/research.html">Research Directions</a></h3>
      <p>Open problems: formal verification, privacy-preserving reasoning, LLM+HDC hybrids.</p>
    </div>
  </div>

  <h2>Mathematical Guarantees</h2>

  <p>Regardless of which strategy is used, the following properties are guaranteed:</p>

  <ul>
    <li><strong>Closure:</strong> All operations produce valid hypervectors</li>
    <li><strong>Determinism:</strong> Same inputs always produce same outputs</li>
    <li><strong>Approximate Reversibility:</strong> BIND is self-inverse; BUNDLE is approximately recoverable</li>
    <li><strong>Compositionality:</strong> Complex structures are built from simple parts</li>
    <li><strong>Graceful Degradation:</strong> Accuracy decreases smoothly as capacity is reached</li>
  </ul>

  <h2>Holographic Representations</h2>

  <p>AGISystem2's approach to knowledge representation has deep roots in <strong>holographic computing</strong> - a paradigm where information is distributed across the entire representation rather than localized in specific positions. <a href="holographic-representations.html">Read the full documentation &rarr;</a></p>

  <h3>Historical Context</h3>

  <p>The concept of holographic representations in computing traces back to several foundational works:</p>

  <ul>
    <li><strong>1960s:</strong> Holography principles (Gabor) inspire distributed representation ideas</li>
    <li><strong>1990s:</strong> Plate's Holographic Reduced Representations (HRR) - circular convolution binding</li>
    <li><strong>2000s:</strong> Kanerva's Hyperdimensional Computing - binary vectors with XOR binding</li>
    <li><strong>2010s:</strong> Vector Symbolic Architectures (VSA) as unifying framework</li>
  </ul>

  <div class="alert alert-info">
    <strong>Key Insight:</strong> Just as in optical holography where each fragment contains information about the whole image, holographic computing distributes information across all dimensions of the vector. This provides natural noise tolerance and content-addressable memory.
  </div>

  <h3>The Holographic Property</h3>

  <p>When we bind two concepts A and B, the result contains "holographic traces" of both:</p>

  <pre><code>// A BIND B is "holographically" related to both A and B
// Unbinding recovers the original:
(A BIND B) BIND B = A    // B is the "key" to recover A
(A BIND B) BIND A = B    // A is the "key" to recover B</code></pre>

  <p>This is analogous to optical holography where the reference beam is needed to reconstruct the image.</p>

  <h3>A Programming Language for Holographic Computation</h3>

  <p>AGISystem2's DSL (Domain Specific Language) provides high-level primitives for holographic computation:</p>

  <table>
    <tr>
      <th>DSL Primitive</th>
      <th>Holographic Operation</th>
      <th>Purpose</th>
    </tr>
    <tr>
      <td><code>relation arg1 arg2</code></td>
      <td>Encode structured fact</td>
      <td>Create holographic record</td>
    </tr>
    <tr>
      <td><code>query relation ?var</code></td>
      <td>Holographic unbinding</td>
      <td>Content-addressable retrieval</td>
    </tr>
    <tr>
      <td><code>prove goal</code></td>
      <td>Recursive unbinding + matching</td>
      <td>Logical inference via retrieval</td>
    </tr>
    <tr>
      <td><code>bundle [facts]</code></td>
      <td>Superposition of records</td>
      <td>Build knowledge base</td>
    </tr>
  </table>

  <p>The DSL abstracts away the underlying vector operations, allowing programmers to think in terms of relations, rules, and queries while the system performs holographic computation underneath.</p>

  <h3>Backtracking and Search</h3>

  <p>The holographic representation enables interesting possibilities for search and backtracking:</p>

  <ul>
    <li><strong>Parallel Retrieval:</strong> All facts matching a query pattern are activated simultaneously</li>
    <li><strong>Confidence-Ordered Results:</strong> Multiple candidates emerge ranked by similarity</li>
    <li><strong>State Preservation:</strong> The vector state before binding can be preserved for backtracking</li>
    <li><strong>Compositional Rollback:</strong> Since BIND is self-inverse, computations can be "undone" algebraically</li>
  </ul>

  <h3>Connections to Homomorphic Encryption</h3>

  <p>There is an intriguing parallel between holographic representations and homomorphic encryption:</p>

  <div class="alert alert-warning">
    <strong>Conceptual Link:</strong> Just as homomorphic encryption allows computation on encrypted data without decryption, holographic binding allows <em>composition</em> of concepts without "unpacking" their internal structure. The vector for "loves(John, Mary)" is meaningful without explicitly storing "John" or "Mary" as separate retrievable entities.
  </div>

  <p>This suggests potential applications in:</p>

  <ul>
    <li><strong>Privacy-Preserving Reasoning:</strong> Queries can be answered without exposing raw facts</li>
    <li><strong>Secure Knowledge Sharing:</strong> Holographic representations can be shared without revealing atomic concepts (if concept vectors are kept private)</li>
    <li><strong>Deterministic Initialization:</strong> Using cryptographic hashes for concept vector generation provides both determinism and privacy</li>
  </ul>

  <p>While not equivalent to formal homomorphic encryption, the holographic paradigm offers similar "compute without decode" properties in a probabilistic, similarity-based setting. <a href="privacy-hdc.html">Read the full analysis of HDC privacy properties &rarr;</a></p>

  <h2>Epistemological Foundations</h2>

  <div class="alert alert-warning" style="margin: 20px 0;">
    <strong><a href="grounding-problem.html">The Symbol Grounding Problem</a></strong> &mdash; An honest assessment of what formal systems can and cannot achieve. Why we adopt a meta-rational approach: pragmatic utility over theoretical idealization. No magic, no singularity, just useful engineering.
  </div>

  <h2>Further Reading</h2>

  <ul>
    <li><a href="nl2dsl.html"><strong>NL2DSL Translation</strong></a> - Natural language to DSL translation patterns and API</li>
    <li><a href="hrr-comparison.html"><strong>HRR Comparison</strong></a> - Are our strategies Holographic Reduced Representations? (Assessment)</li>
    <li><a href="grounding-problem.html">The Symbol Grounding Problem</a> - Honest limitations and the meta-rational approach</li>
    <li><a href="deterministic-vectors.html">Deterministic Vector Generation</a> - How atom names become hypervectors (hash, PRNG, privacy)</li>
    <li><a href="trustworthy-ai/index.html">Trustworthy AI Patterns</a> - Building verifiable, explainable AI systems</li>
    <li><a href="privacy-hdc.html">Privacy-Preserving HDC</a> - Towards homomorphic reasoning</li>
    <li><a href="concepts/index.html">Theoretical Concepts</a> - GF(2), Jaccard, Min-Hash explained</li>
    <li><a href="strategies/dense-binary.html">Dense-Binary Strategy - In-Depth Theory</a></li>
    <li><a href="strategies/sparse-polynomial.html">SPHDC Strategy - In-Depth Theory</a> (Original)</li>
    <li><a href="strategies/metric-affine.html">Metric-Affine Strategy - Fuzzy-Boolean HDC</a> (Original)</li>
    <li><a href="strategies/sphdc-analysis.html">SPHDC Theoretical Analysis</a> - Mathematical deep-dive</li>
    <li><a href="../specsLoader.html?spec=DS01-Theoretical-Foundation.md">DS01 - Theoretical Foundation Specification</a></li>
    <li><a href="../specsLoader.html?spec=DS09-Core-HDC-Implementation.md">DS09 - Core HDC Implementation Specification</a></li>
    <li>Kanerva, P. (2009). "Hyperdimensional Computing: An Introduction to Computing in Distributed Representations"</li>
    <li>Plate, T. (2003). "Holographic Reduced Representation: Distributed Representation for Cognitive Structures"</li>
    <li>Gayler, R. (2003). "Vector Symbolic Architectures Answer Jackendoff's Challenges for Cognitive Neuroscience"</li>
  </ul>

  <div class="footer-nav">
    <p>HDC provides the mathematical foundation for deterministic, explainable AI with formal guarantees.</p>
  </div>
  </div>
</body>
</html>
