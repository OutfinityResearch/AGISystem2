<!doctype html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Theory - AGISystem2</title>
  <link rel="stylesheet" href="../reference/style.css">
</head>
<body>
  <div class="page">
  <div class="nav-header">
    <h1>Theoretical Foundation</h1>
    <small>
      <a href="../index.html">Home</a> &middot;
      <a href="../architecture/index.html">Architecture</a> &middot;
      <a href="../reasoning/index.html">Reasoning</a> &middot;
      <a href="index.html"><strong>Theory</strong></a> &middot;
      <a href="../syntax/index.html">Syntax</a> &middot;
      <a href="../api/index.html">APIs</a> &middot;
      <a href="../wiki/index.html">Wiki</a> &middot;
      <a href="../specs/matrix.html">Specs</a> &middot;
      <a href="../research/index.html">Research</a>
    </small>
    <small>Pragmatic meaning for natural language theories</small>
  </div>

  <div class="section-intro">
    <p><strong>AGISystem2</strong> is a platform for exploring multiple strategies for representing and using knowledge extracted from natural language. The practical goal is to formalize scientific, technical, and creative “theories” into a small DSL so they can be <em>used</em>: queried, tested, compared, composed, audited, and revised.</p>
    <p>We treat “meaning” as <strong>formal pragmatics</strong>—a family of engineered, context-sensitive interpretation modes—rather than assuming a single, final, universal semantics. The same text can support different tasks (explain vs. predict vs. verify vs. design), and the system is built to make those task contracts explicit.</p>
  </div>

  <div class="alert alert-info">
    <strong>Terminology:</strong>
    <ul>
      <li><strong>VSA</strong> (Vector Symbolic Architectures) is the umbrella family: represent symbols and structure with high‑dimensional vectors and algebraic operations.</li>
      <li><strong>HDC</strong> (Hyperdimensional Computing) is a closely related term, often used interchangeably in practice; many HDC systems are VSAs.</li>
      <li><strong>HRR</strong> (Holographic Reduced Representations, Plate) is a classic VSA variant (e.g., circular convolution binding), historically influential for “holographic” composition and retrieval.</li>
    </ul>
    <p>AGISystem2 uses VSA/HDC ideas as one major axis, but the project is explicitly a <em>strategy lab</em>: different representation strategies (including lossless and hybrid approaches) can be swapped and evaluated under the same DSL and test suite.</p>
  </div>

  <h2>Quick Links</h2>

  <div class="section-grid">
    <div class="section-card">
      <h3><a href="formal-pragmatics.html">Formal Pragmatics</a></h3>
      <p>Why we treat meaning as engineered “use contracts”, not a single final semantics.</p>
    </div>
    <div class="section-card">
      <h3><a href="nl2dsl.html">NL&rarr;DSL</a></h3>
      <p>Translate natural language into DSL so theories become executable and testable.</p>
    </div>
    <div class="section-card">
      <h3>Strategies</h3>
      <p>Same DSL, different representations:</p>
      <ul>
        <li><a href="strategies/dense-binary.html">Dense-Binary</a></li>
        <li><a href="strategies/sparse-polynomial.html">SPHDC</a></li>
        <li><a href="strategies/metric-affine.html">Metric-Affine</a></li>
        <li><a href="strategies/metric-affine-elastic.html">EMA</a></li>
        <li><a href="strategies/exact.html">EXACT</a></li>
      </ul>
    </div>
    <div class="section-card">
      <h3><a href="hrr-comparison.html">HRR Comparison</a></h3>
      <p>How our strategies relate (or don’t) to classic HRR/VSA formulations.</p>
    </div>
    <div class="section-card">
      <h3><a href="holographic-representations.html">Holographic Notes</a></h3>
      <p>Background on “distributed” representations and similarity-first retrieval.</p>
    </div>
    <div class="section-card">
      <h3><a href="deterministic-vectors.html">Deterministic Vectors</a></h3>
      <p>How names become vectors (hashing/PRNG), plus reproducibility and privacy notes.</p>
    </div>
    <div class="section-card">
      <h3><a href="trustworthy-ai/index.html">Trustworthy AI</a></h3>
      <p>Patterns for verification, explainability, compliance, and agent planning.</p>
    </div>
    <div class="section-card">
      <h3><a href="grounding-problem.html">Grounding Problem</a></h3>
      <p>Honest limitations and why we take a pragmatic, engineering-first stance.</p>
    </div>
  </div>

  <h2>What This Project Tries To Do</h2>

  <div class="section-grid">
    <div class="section-card">
      <h3>Formalize Theories</h3>
      <p>Turn informal statements into compact DSL artifacts: relations, rules, constraints, and reusable “theory modules”.</p>
    </div>
    <div class="section-card">
      <h3>Use Theories</h3>
      <p>Support pragmatic tasks: ask queries, run proof attempts, detect contradictions, track assumptions, and generate structured explanations.</p>
    </div>
    <div class="section-card">
      <h3>Compare Strategies</h3>
      <p>Run the same workloads across multiple backends (vector‑symbolic, hybrid, exact) and measure quality, stability, and cost.</p>
    </div>
    <div class="section-card">
      <h3>Engineer Trust</h3>
      <p>Prefer deterministic behavior, reproducibility, and inspectable intermediate states over “mysterious” end‑to‑end predictions.</p>
    </div>
  </div>

  <h2>Why Vector-Symbolic Methods?</h2>

  <div class="section-grid">
    <div class="section-card">
      <h3>Determinism</h3>
      <p>Unlike probabilistic neural networks, HDC operations are fully deterministic. The same input always produces the same output, enabling perfect reproducibility and debugging.</p>
    </div>

    <div class="section-card">
      <h3>Compositionality</h3>
      <p>Complex structures can be built from simple parts using only two operations (Bind and Bundle). This enables systematic construction and deconstruction of knowledge.</p>
    </div>

    <div class="section-card">
      <h3>Noise Tolerance</h3>
      <p>High-dimensional representations are naturally robust to noise and errors. Small perturbations don't significantly affect similarity comparisons.</p>
    </div>

    <div class="section-card">
      <h3>Efficiency</h3>
      <p>Core operations are extremely fast on modern hardware. The mathematical structure allows for hardware-friendly implementations.</p>
    </div>
  </div>

  <h2>Core Concepts</h2>

  <h3>The Hypervector</h3>

  <p>The fundamental data structure is a <strong>hypervector</strong> - a high-dimensional representation where each concept occupies a unique region in the vector space.</p>

  <div class="alert alert-info">
    <strong>Key Insight:</strong> In high-dimensional spaces, randomly generated vectors are almost orthogonal to each other. This "quasi-orthogonality" property means any new concept gets a representation that doesn't interfere with existing ones.
  </div>

  <h3>The Core Operations</h3>

  <table>
    <tr>
      <th>Operation</th>
      <th>Purpose</th>
      <th>Mathematical Property</th>
    </tr>
    <tr>
      <td><strong>BIND</strong></td>
      <td>Create associations between concepts</td>
      <td>Supports cancellation for self-inverse bindings (e.g. XOR). Other strategies use a distinct UNBIND and may require decoding/cleanup.</td>
    </tr>
    <tr>
      <td><strong>UNBIND</strong></td>
      <td>Remove a known component from a composite</td>
      <td>Inverse of BIND; some strategies implement UNBIND ≡ BIND, but this is not required by the contract</td>
    </tr>
    <tr>
      <td><strong>BUNDLE</strong></td>
      <td>Combine multiple vectors into one</td>
      <td>Result is similar to all inputs</td>
    </tr>
    <tr>
      <td><strong>SIMILARITY</strong></td>
      <td>Measure relatedness</td>
      <td>Range [0, 1], 0.5 = unrelated</td>
    </tr>
  </table>

  <h3>Position Vectors</h3>

  <p>Because BIND is commutative, we need a mechanism to distinguish argument positions. Position vectors (Pos1, Pos2, ..., Pos20) solve this:</p>

  <pre><code>// Without positions: loves(John, Mary) = loves(Mary, John) (WRONG!)
// With positions:
fact = Loves BIND (Pos1 BIND John) BIND (Pos2 BIND Mary)  // loves(John, Mary)
fact = Loves BIND (Pos1 BIND Mary) BIND (Pos2 BIND John)  // loves(Mary, John) - DIFFERENT!</code></pre>

  <h3>The Reasoning Equation</h3>

  <p>All queries reduce to this fundamental principle:</p>

  <div class="alert alert-info">
    <strong>Answer &asymp; UNBIND(Knowledge, QueryKey)</strong>
    <p><code>QueryKey</code> is the part of the query you already know (relation + bound arguments). UNBIND removes that key from the KB composite to reveal the unknown parts. In XOR-based strategies, UNBIND is often implemented by calling BIND again. In other strategies (e.g. lossless EXACT), UNBIND yields a residual that must be projected back to entity candidates via strategy-aware decoding/cleanup.</p>
  </div>

  <h2>HDC Strategies</h2>

  <p>AGISystem2 implements multiple HDC strategies, each with different internal representations while maintaining the same mathematical contract:</p>

  <div class="section-grid">
    <div class="section-card">
      <h3>Dense-Binary</h3>
      <p>Classic HDC with fixed-length binary vectors. Uses XOR for binding and majority vote for bundling.</p>
      <p><a href="strategies/dense-binary.html">Full Documentation &rarr;</a></p>
    </div>

    <div class="section-card">
      <h3>Sparse Polynomial (SPHDC)</h3>
      <p>Set-based HDC with k integer exponents. Uses Cartesian XOR for binding and Jaccard index for similarity.</p>
      <p><a href="strategies/sparse-polynomial.html">Full Documentation &rarr;</a></p>
    </div>

    <div class="section-card" style="background: linear-gradient(135deg, #fff3e022 0%, #ffe0b222 100%);">
      <h3>Metric-Affine</h3>
      <p>Compact 32-byte vectors over Z₂₅₆. Uses XOR binding with L₁ similarity and arithmetic mean bundling. Fuzzy-Boolean Hyper-Lattice.</p>
      <p><a href="strategies/metric-affine.html">Full Documentation &rarr;</a></p>
    </div>

    <div class="section-card" style="background: linear-gradient(135deg, #e0f2f122 0%, #b2dfdb22 100%);">
      <h3>Metric-Affine Elastic (EMA)</h3>
      <p>Metric-Affine extension with chunked bundling and optional elastic geometry for large KB superpositions.</p>
      <p><a href="strategies/metric-affine-elastic.html">Full Documentation &rarr;</a></p>
    </div>

    <div class="section-card" style="background: linear-gradient(135deg, #e8eaf622 0%, #c5cae922 100%);">
      <h3>EXACT (Exact-Sparse)</h3>
      <p>Lossless bitset-polynomial HDC over <code>BigInt</code> monomials. Session-local atom IDs (appearance index dictionary). UNBIND is not required to equal BIND.</p>
      <p><a href="strategies/exact.html">Full Documentation &rarr;</a></p>
    </div>
  </div>

  <h2>HRR Comparison: Original Contributions</h2>

  <p>AGISystem2 implements five HDC strategies. Two are <strong>original contributions</strong> not found in existing literature, one is an elastic extension of Metric-Affine, and one (EXACT) is a lossless, session-local “bitset polynomial” exploration. How do they relate to Tony Plate's Holographic Reduced Representations (HRR)?</p>

  <p style="margin-top: 10px;">
    Strategy pages:
    <a href="strategies/dense-binary.html">Dense-Binary</a>,
    <a href="strategies/sparse-polynomial.html">SPHDC</a>,
    <a href="strategies/metric-affine.html">Metric-Affine</a>,
    <a href="strategies/metric-affine-elastic.html">EMA</a>,
    <a href="strategies/exact.html">EXACT</a>.
  </p>

  <div class="section-grid">
    <div class="section-card">
      <h3><a href="hrr-comparison.html">HRR vs. Our Strategies</a></h3>
      <p>Detailed analysis of Dense-Binary (standard), Sparse Polynomial (novel), and Metric-Affine (novel) against classic HRR, with notes on the EMA extension.</p>
    </div>

    <div class="section-card">
      <h3><a href="strategies/dense-binary.html">Dense-Binary</a></h3>
      <p><strong>STANDARD:</strong> A classic VSA/HDC baseline: fixed-length binary vectors, XOR binding, majority-vote bundling. Useful as a reference point when comparing to HRR-style binding and to our novel strategies.</p>
    </div>

    <div class="section-card" style="background: linear-gradient(135deg, #f3e5f522 0%, #ce93d822 100%);">
      <h3><a href="strategies/sparse-polynomial.html">Sparse Polynomial (SPHDC)</a></h3>
      <p><strong>ORIGINAL:</strong> Set-based HDC with Cartesian XOR binding and Min-Hash sparsification. NOT HRR - a novel paradigm.</p>
    </div>

    <div class="section-card" style="background: linear-gradient(135deg, #fff3e022 0%, #ffe0b222 100%);">
      <h3><a href="strategies/metric-affine.html">Metric-Affine</a></h3>
      <p><strong>ORIGINAL:</strong> Fuzzy-Boolean hybrid combining XOR binding with continuous bundling. HRR-inspired but novel.</p>
    </div>

    <div class="section-card" style="background: linear-gradient(135deg, #e0f2f122 0%, #b2dfdb22 100%);">
      <h3><a href="strategies/metric-affine-elastic.html">Metric-Affine Elastic (EMA)</a></h3>
      <p><strong>EXTENSION:</strong> Chunked bundling + elastic geometry for stable superposition at scale.</p>
    </div>

    <div class="section-card" style="background: linear-gradient(135deg, #e8eaf622 0%, #c5cae922 100%);">
      <h3><a href="strategies/exact.html">EXACT (Exact-Sparse)</a></h3>
      <p><strong>EXPLORATION:</strong> Lossless bitset-polynomial strategy (no PRNG/hashing for atom IDs inside a session). Uses a quotient-like UNBIND instead of self-inverse XOR.</p>
    </div>
  </div>

  <div class="alert alert-info">
    <strong>Summary:</strong> Dense-Binary is standard VSA/HDC. Sparse Polynomial and Metric-Affine are original contributions developed for AGISystem2, Metric-Affine Elastic extends Metric-Affine for large KB superpositions, and EXACT explores a fully lossless session-local representation.
  </div>

  <h2>Trustworthy AI</h2>

  <p>HDC's deterministic, explainable nature makes it ideal for building <strong>trustworthy AI systems</strong>&mdash;AI that can be verified, audited, and understood.</p>

  <div class="section-grid">
    <div class="section-card" style="background: linear-gradient(135deg, #4caf5022 0%, #8bc34a22 100%);">
      <h3><a href="trustworthy-ai/index.html">Trustworthy AI Overview</a></h3>
      <p>How HDC enables verifiable, explainable, auditable AI. Common patterns and approaches.</p>
    </div>

    <div class="section-card">
      <h3><a href="trustworthy-ai/agent-planning.html">Agent Planning</a></h3>
      <p>Formal tool semantics, plan verification before execution, failure diagnosis.</p>
    </div>

    <div class="section-card">
      <h3><a href="trustworthy-ai/compliance.html">Compliance & Verification</a></h3>
      <p>Real-time regulatory checking, automatic audit trails, remediation guidance.</p>
    </div>

    <div class="section-card">
      <h3><a href="trustworthy-ai/research.html">Research Directions</a></h3>
      <p>Open problems: formal verification, privacy-preserving reasoning, LLM+HDC hybrids.</p>
    </div>
  </div>

  <h2>Mathematical Guarantees</h2>

  <p>Regardless of which strategy is used, the following properties are guaranteed:</p>

  <ul>
    <li><strong>Closure:</strong> All operations produce valid hypervectors</li>
    <li><strong>Determinism:</strong> Same inputs always produce same outputs</li>
    <li><strong>Cancellation (strategy-dependent):</strong> Some strategies have self-inverse binding (XOR); others use a distinct UNBIND and decoding/cleanup</li>
    <li><strong>Compositionality:</strong> Complex structures are built from simple parts</li>
    <li><strong>Graceful Degradation:</strong> Accuracy decreases smoothly as capacity is reached</li>
  </ul>

  <h2>Holographic Representations</h2>

  <p>AGISystem2's approach to knowledge representation has deep roots in <strong>holographic computing</strong> - a paradigm where information is distributed across the entire representation rather than localized in specific positions. <a href="holographic-representations.html">Read the full documentation &rarr;</a></p>

  <h3>Historical Context</h3>

  <p>The concept of holographic representations in computing traces back to several foundational works:</p>

  <ul>
    <li><strong>1960s:</strong> Holography principles (Gabor) inspire distributed representation ideas</li>
    <li><strong>1990s:</strong> Plate's Holographic Reduced Representations (HRR) - circular convolution binding</li>
    <li><strong>2000s:</strong> Kanerva's Hyperdimensional Computing - binary vectors with XOR binding</li>
    <li><strong>2010s:</strong> Vector Symbolic Architectures (VSA) as unifying framework</li>
  </ul>

  <div class="alert alert-info">
    <strong>Key Insight:</strong> Just as in optical holography where each fragment contains information about the whole image, holographic computing distributes information across all dimensions of the vector. This provides natural noise tolerance and content-addressable memory.
  </div>

  <h3>The Holographic Property</h3>

  <p>When we bind two concepts A and B, the result contains "holographic traces" of both:</p>

  <pre><code>// A BIND B is "holographically" related to both A and B
// For XOR/self-inverse bindings, unbinding can be done by binding again:
(A BIND B) BIND B = A    // B is the "key" to recover A
(A BIND B) BIND A = B    // A is the "key" to recover B</code></pre>

  <p>This is analogous to optical holography where the reference beam is needed to reconstruct the image.</p>

  <h3>A Programming Language for Holographic Computation</h3>

  <p>AGISystem2's DSL (Domain Specific Language) provides high-level primitives for holographic computation:</p>

  <table>
    <tr>
      <th>DSL Primitive</th>
      <th>Holographic Operation</th>
      <th>Purpose</th>
    </tr>
    <tr>
      <td><code>relation arg1 arg2</code></td>
      <td>Encode structured fact</td>
      <td>Create holographic record</td>
    </tr>
    <tr>
      <td><code>query relation ?var</code></td>
      <td>Holographic unbinding</td>
      <td>Content-addressable retrieval</td>
    </tr>
    <tr>
      <td><code>prove goal</code></td>
      <td>Recursive unbinding + matching</td>
      <td>Logical inference via retrieval</td>
    </tr>
    <tr>
      <td><code>bundle [facts]</code></td>
      <td>Superposition of records</td>
      <td>Build knowledge base</td>
    </tr>
  </table>

  <p>The DSL abstracts away the underlying vector operations, allowing programmers to think in terms of relations, rules, and queries while the system performs holographic computation underneath.</p>

  <h3>Backtracking and Search</h3>

  <p>The holographic representation enables interesting possibilities for search and backtracking:</p>

  <ul>
    <li><strong>Parallel Retrieval:</strong> All facts matching a query pattern are activated simultaneously</li>
    <li><strong>Confidence-Ordered Results:</strong> Multiple candidates emerge ranked by similarity</li>
    <li><strong>State Preservation:</strong> The vector state before binding can be preserved for backtracking</li>
    <li><strong>Compositional Rollback:</strong> For self-inverse bindings (e.g. XOR), computations can be “undone” algebraically; other strategies require explicit UNBIND/decoding</li>
  </ul>

  <h3>Connections to Homomorphic Encryption</h3>

  <p>There is an intriguing parallel between holographic representations and homomorphic encryption:</p>

  <div class="alert alert-warning">
    <strong>Conceptual Link:</strong> Just as homomorphic encryption allows computation on encrypted data without decryption, holographic binding allows <em>composition</em> of concepts without "unpacking" their internal structure. The vector for "loves(John, Mary)" is meaningful without explicitly storing "John" or "Mary" as separate retrievable entities.
  </div>

  <p>This suggests potential applications in:</p>

  <ul>
    <li><strong>Privacy-Preserving Reasoning:</strong> Queries can be answered without exposing raw facts</li>
    <li><strong>Secure Knowledge Sharing:</strong> Holographic representations can be shared without revealing atomic concepts (if concept vectors are kept private)</li>
    <li><strong>Deterministic Initialization:</strong> Using cryptographic hashes for concept vector generation provides both determinism and privacy</li>
  </ul>

  <p>While not equivalent to formal homomorphic encryption, the holographic paradigm offers similar "compute without decode" properties in a probabilistic, similarity-based setting. <a href="privacy-hdc.html">Read the full analysis of HDC privacy properties &rarr;</a></p>

  <h2>Epistemological Foundations</h2>

  <div class="alert alert-warning" style="margin: 20px 0;">
    <strong><a href="grounding-problem.html">The Symbol Grounding Problem</a></strong> &mdash; An honest assessment of what formal systems can and cannot achieve. Why we adopt a meta-rational approach: pragmatic utility over theoretical idealization. No magic, no singularity, just useful engineering.
  </div>

  <h2>Further Reading</h2>

  <ul>
    <li><a href="formal-pragmatics.html"><strong>Formal Pragmatics (Meaning as Use)</strong></a> - Why we avoid a “single final semantics” and what we build instead</li>
    <li><a href="nl2dsl.html"><strong>NL2DSL Translation</strong></a> - Natural language to DSL translation patterns and API</li>
    <li><a href="hrr-comparison.html"><strong>HRR Comparison</strong></a> - Are our strategies Holographic Reduced Representations? (Assessment)</li>
    <li><a href="grounding-problem.html">The Symbol Grounding Problem</a> - Honest limitations and the meta-rational approach</li>
    <li><a href="deterministic-vectors.html">Deterministic Vector Generation</a> - How atom names become hypervectors (hash, PRNG, privacy)</li>
    <li><a href="trustworthy-ai/index.html">Trustworthy AI Patterns</a> - Building verifiable, explainable AI systems</li>
    <li><a href="privacy-hdc.html">Privacy-Preserving HDC</a> - Towards homomorphic reasoning</li>
    <li><a href="concepts/index.html">Theoretical Concepts</a> - GF(2), Jaccard, Min-Hash explained</li>
    <li><a href="strategies/dense-binary.html">Dense-Binary Strategy - In-Depth Theory</a></li>
    <li><a href="strategies/sparse-polynomial.html">SPHDC Strategy - In-Depth Theory</a> (Original)</li>
    <li><a href="strategies/metric-affine.html">Metric-Affine Strategy - Fuzzy-Boolean HDC</a> (Original)</li>
    <li><a href="strategies/metric-affine-elastic.html">Metric-Affine Elastic Strategy - Chunked Bundling + Elastic Geometry</a> (Extension)</li>
    <li><a href="strategies/exact.html">EXACT Strategy - Lossless Bitset-Polynomial</a> (Exploration)</li>
    <li><a href="strategies/sphdc-analysis.html">SPHDC Theoretical Analysis</a> - Mathematical deep-dive</li>
    <li><a href="../specsLoader.html?spec=DS/DS01-Theoretical-Foundation.md">DS01 - Theoretical Foundation Specification</a></li>
    <li><a href="../specsLoader.html?spec=DS/DS09-Core-HDC-Implementation.md">DS09 - Core HDC Implementation Specification</a></li>
    <li>Kanerva, P. (2009). "Hyperdimensional Computing: An Introduction to Computing in Distributed Representations"</li>
    <li>Plate, T. (2003). "Holographic Reduced Representation: Distributed Representation for Cognitive Structures"</li>
    <li>Gayler, R. (2003). "Vector Symbolic Architectures Answer Jackendoff's Challenges for Cognitive Neuroscience"</li>
  </ul>

  <div class="footer-nav">
    <p>AGISystem2 explores multiple knowledge-representation strategies to make natural language theories usable as engineered artifacts.</p>
  </div>
  </div>
</body>
</html>
