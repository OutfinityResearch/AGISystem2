<!doctype html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Synthetic Data Generation - Trustworthy AI - AGISystem2</title>
  <link rel="stylesheet" href="../../reference/style.css">
  <style>
    .pipeline-box {
      background: #f8f9fa;
      border: 1px solid #dee2e6;
      border-radius: 8px;
      padding: 20px;
      margin: 20px 0;
    }
    .code-block {
      background: #2d2d2d;
      color: #f8f8f2;
      padding: 15px;
      border-radius: 4px;
      overflow-x: auto;
      font-family: monospace;
      font-size: 13px;
    }
    .highlight-theory { color: #50fa7b; }
    .highlight-gen { color: #ff79c6; }
    .highlight-output { color: #f1fa8c; }
    .research-box {
      background: #e7f3ff;
      border: 1px solid #0066cc;
      border-left: 4px solid #0066cc;
      padding: 15px;
      margin: 15px 0;
    }
    .warning-box {
      background: #fff3cd;
      border: 1px solid #ffc107;
      border-left: 4px solid #ffc107;
      padding: 15px;
      margin: 15px 0;
    }
    .benefit-card {
      background: #d4edda;
      border: 1px solid #28a745;
      padding: 15px;
      margin: 10px 0;
      border-radius: 4px;
    }
  </style>
</head>
<body>
  <div class="page">
  <div class="nav-header">
    <h1>Synthetic Data Generation from Theories <span class="badge badge-warning">Research</span></h1>
    <small>
      <a href="../../index.html">Home</a> &middot;
      <a href="../index.html">Theory</a> &middot;
      <a href="index.html">Trustworthy AI</a> &middot;
      <a href="synthetic-data.html">Synthetic Data</a>
    </small>
    <small>Training System 1 (LLMs) with System 2 knowledge</small>
  </div>

  <div class="section-intro">
    <p><strong>Theories as training data factories.</strong> AGISystem2's formal theories can be used to generate training examples for LLMs and other neural systems. Correctness is with respect to the theory and requires an external generation pipeline.</p>
  </div>

  <div class="warning-box">
    <strong>Status:</strong> Research pattern (DS08). Synthetic data generation pipelines are not shipped in the runtime.
  </div>

  <h2>1. The System 1 / System 2 Integration</h2>

  <p>In cognitive science terminology:</p>

  <table>
    <tr>
      <th>Aspect</th>
      <th>System 1 (LLMs)</th>
      <th>System 2 (AGISystem2)</th>
    </tr>
    <tr>
      <td>Processing</td>
      <td>Fast, intuitive</td>
      <td>Slow, deliberate</td>
    </tr>
    <tr>
      <td>Knowledge</td>
      <td>Implicit in weights</td>
      <td>Explicit in theories</td>
    </tr>
    <tr>
      <td>Strength</td>
      <td>Language fluency</td>
      <td>Logical rigor</td>
    </tr>
    <tr>
      <td>Weakness</td>
      <td>Hallucination, inconsistency</td>
      <td>Brittle to novel phrasing</td>
    </tr>
  </table>

  <div class="research-box">
    <strong>Key Insight:</strong> Use AGISystem2's formal theories to generate training data that teaches LLMs to reason correctly within specific domains. The LLM learns to approximate the formal system's behavior.
  </div>

  <h2>2. The Synthetic Data Pipeline</h2>

  <div class="pipeline-box">
    <h3>Theory → Examples → Training Data</h3>
    <ol>
      <li><strong>Define Theory:</strong> Encode domain knowledge as formal theory</li>
      <li><strong>Generate Queries:</strong> Systematically create all valid queries</li>
      <li><strong>Execute Reasoning:</strong> Get answers with proof traces</li>
      <li><strong>Verbalize:</strong> Convert to natural language Q&A pairs</li>
      <li><strong>Train LLM:</strong> Fine-tune on generated examples</li>
    </ol>
  </div>

  <h3>Example: Generating Animal Taxonomy Data</h3>

  <div class="code-block">
<span class="highlight-theory">// Theory Definition</span>
Dog IS_A Animal
Cat IS_A Animal
Animal IS_A LivingThing
Spot instanceOf Dog
Whiskers instanceOf Cat

<span class="highlight-gen">// Generate all valid inferences</span>
→ Dog IS_A LivingThing (transitive)
→ Spot IS_A Animal (instance + inheritance)
→ Spot IS_A LivingThing (transitive chain)
→ Whiskers IS_A Animal
→ Whiskers IS_A LivingThing

<span class="highlight-output">// Generated Q&A pairs</span>
Q: Is Spot an animal?
A: Yes, because Spot is a dog, and all dogs are animals.

Q: Is Whiskers a living thing?
A: Yes, because Whiskers is a cat, cats are animals,
   and animals are living things.

Q: Is Spot a cat?
A: No, there is no evidence that Spot is a cat.
   Spot is known to be a dog.
  </div>

  <h2>3. Types of Generated Data</h2>

  <h3>3.1 Direct Fact Questions</h3>
  <div class="code-block">
Q: What type of thing is Spot?
A: Spot is a dog.
[Source: explicit fact in KB]
  </div>

  <h3>3.2 Inference Questions</h3>
  <div class="code-block">
Q: Is Spot a mammal?
A: Yes, by the following reasoning:
   1. Spot is a dog (known fact)
   2. Dogs are mammals (taxonomic rule)
   Therefore, Spot is a mammal.
  </div>

  <h3>3.3 Negative Examples</h3>
  <div class="code-block">
Q: Is Spot a plant?
A: No. Spot is a dog, and dogs are animals.
   Animals and plants are disjoint categories.
  </div>

  <h3>3.4 Explanation-with-Answer</h3>
  <div class="code-block">
Q: Explain why all dogs are living things.
A: Dogs are living things because:
   - Dogs are animals (taxonomic classification)
   - Animals are living things (biological category)
   - By transitive inheritance, dogs are living things.
  </div>

  <h3>3.5 Counterfactual Reasoning</h3>
  <div class="code-block">
Q: If dogs were not animals, would Spot still be a living thing?
A: We cannot conclude Spot is a living thing without
   the Dog→Animal→LivingThing inference chain.
   Additional facts about Spot would be needed.
  </div>

  <h2>4. Benefits of Theory-Generated Data</h2>

  <div class="benefit-card">
    <h4>Theory-Relative Correctness</h4>
    <p>Generated examples are correct with respect to the formal theory (assuming the theory is valid). External generation pipelines should preserve this constraint.</p>
  </div>

  <div class="benefit-card">
    <h4>Unlimited Quantity</h4>
    <p>Theories can generate combinatorially many examples. Add 10 new entities and get thousands of new training pairs.</p>
  </div>

  <div class="benefit-card">
    <h4>Systematic Coverage</h4>
    <p>Generate examples that cover all inference paths, all edge cases, all negative examples. No gaps in training coverage.</p>
  </div>

  <div class="benefit-card">
    <h4>Controllable Difficulty</h4>
    <p>Generate examples with 1-step reasoning, 2-step, n-step. Control the complexity of the training curriculum.</p>
  </div>

  <div class="benefit-card">
    <h4>Domain Adaptation</h4>
    <p>Same pipeline works for any domain: medical, legal, scientific, financial. Just change the theory.</p>
  </div>

  <h2>5. Architecture for Data Generation</h2>

  <pre><code>
+--------------------------------------------------+
|             Natural Language Generator            |
|    Proof traces → fluent Q&A pairs                |
+--------------------------------------------------+
|              Example Enumerator                   |
|    Systematically explore query space             |
+--------------------------------------------------+
|               Reasoning Engine                    |
|    prove() with full traces                       |
+--------------------------------------------------+
|                 Theory Store                      |
|    Domain knowledge in DSL format                 |
+--------------------------------------------------+
  </code></pre>

  <h2>6. Verbalization Strategies</h2>

  <p>Converting formal proofs to natural language:</p>

  <h3>6.1 Template-Based</h3>
  <div class="code-block">
Rule: X IS_A Y
Template: "All {X}s are {Y}s" / "{X} is a type of {Y}"

Fact: entity instanceOf Class
Template: "{entity} is a {Class}"

Inference: X IS_A Y, Y IS_A Z ⟹ X IS_A Z
Template: "{X} is a {Z} because {X} is a {Y}, and {Y}s are {Z}s"
  </div>

  <h3>6.2 LLM-Assisted Verbalization</h3>
  <p>Use an LLM to paraphrase template outputs for variety:</p>
  <div class="code-block">
Template output: "Spot is an animal because Spot is a dog,
                  and all dogs are animals."

LLM paraphrases:
- "Since Spot is a dog, and dogs belong to the animal kingdom,
   Spot is therefore an animal."
- "We know Spot is an animal. Why? Because Spot is a dog,
   and by definition, dogs are animals."
- "Spot, being a dog, falls under the category of animals."
  </div>

  <h2>7. Training Strategies</h2>

  <h3>7.1 Curriculum Learning</h3>
  <p>Start with simple examples, progressively increase complexity:</p>
  <ol>
    <li><strong>Level 1:</strong> Direct fact retrieval</li>
    <li><strong>Level 2:</strong> Single-step inference</li>
    <li><strong>Level 3:</strong> Multi-step chains</li>
    <li><strong>Level 4:</strong> Counterfactuals and negation</li>
    <li><strong>Level 5:</strong> Complex reasoning with multiple rules</li>
  </ol>

  <h3>7.2 Contrastive Examples</h3>
  <p>Generate pairs that highlight distinctions:</p>
  <div class="code-block">
Positive: "Is Spot an animal?" → Yes (dog → animal)
Negative: "Is Spot a plant?" → No (dog ⊥ plant)

Similar: "Is Whiskers an animal?" → Yes (cat → animal)
Contrast: "Is Spot a cat?" → No (Spot is dog, not cat)
  </div>

  <h3>7.3 Explanation Verification</h3>
  <p>Train LLM to generate explanations that can be verified:</p>
  <div class="code-block">
Input: "Why is Spot a living thing?"

Target output (verifiable):
"Spot is a living thing because:
 1. Spot is a dog [can verify: Dog(Spot) in KB]
 2. Dogs are animals [can verify: Dog IS_A Animal]
 3. Animals are living things [can verify: Animal IS_A LivingThing]
 Therefore Spot is a living thing [inference valid]"
  </div>

  <h2>8. Quality Assurance</h2>

  <div class="warning-box">
    <strong>Verification Loop:</strong> After training, test the LLM's outputs against the original formal system. Any divergence indicates either:
    <ul>
      <li>Insufficient training (add more examples)</li>
      <li>Ambiguous verbalization (improve templates)</li>
      <li>Model capacity limits (use larger model or narrower domain)</li>
    </ul>
  </div>

  <h2>9. Research Directions</h2>

  <div class="research-box">
    <strong>Open Questions:</strong>
    <ul>
      <li><strong>Transfer efficiency:</strong> How many examples needed to teach reliable reasoning?</li>
      <li><strong>Generalization:</strong> Does training on theory A help with similar theory B?</li>
      <li><strong>Faithfulness:</strong> Can we guarantee LLM follows formal reasoning patterns?</li>
      <li><strong>Hybrid inference:</strong> When should LLM defer to formal system?</li>
      <li><strong>Active learning:</strong> Which examples are most informative?</li>
    </ul>
  </div>

  <h2>10. Applications</h2>

  <ul>
    <li><strong>Domain-specific assistants:</strong> Legal, medical, financial AI trained on domain theories</li>
    <li><strong>Educational AI:</strong> Tutors that explain reasoning correctly</li>
    <li><strong>Compliance chatbots:</strong> Answer regulatory questions with verifiable reasoning</li>
    <li><strong>Scientific assistants:</strong> Help researchers reason about theories</li>
  </ul>

  <h2>Related Documentation</h2>

  <ul>
    <li><a href="index.html">Trustworthy AI Overview</a></li>
    <li><a href="explainability.html">Explainability</a></li>
    <li><a href="bias-study.html">Bias Study</a></li>
    <li><a href="research.html">Research Directions</a></li>
    <li><a href="../index.html">Theory Overview</a></li>
  </ul>

  <div class="footer-nav">
    <p>
      <a href="explainability.html">&larr; Explainability</a> |
      <a href="bias-study.html">Bias Study &rarr;</a>
    </p>
  </div>
  </div>
</body>
</html>
