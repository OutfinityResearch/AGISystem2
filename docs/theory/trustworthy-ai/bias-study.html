<!doctype html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Bias Study Through Explainability - Trustworthy AI - AGISystem2</title>
  <link rel="stylesheet" href="../../reference/style.css">
  <style>
    .analysis-box {
      background: #f8f9fa;
      border-left: 4px solid #007bff;
      padding: 15px;
      margin: 15px 0;
    }
    .code-block {
      background: #2d2d2d;
      color: #f8f8f2;
      padding: 15px;
      border-radius: 4px;
      overflow-x: auto;
      font-family: monospace;
      font-size: 13px;
    }
    .bias-detected { color: #ff5555; }
    .bias-free { color: #50fa7b; }
    .highlight { color: #f1fa8c; }
    .research-box {
      background: #e7f3ff;
      border: 1px solid #0066cc;
      border-left: 4px solid #0066cc;
      padding: 15px;
      margin: 15px 0;
    }
    .warning-box {
      background: #fff3cd;
      border: 1px solid #ffc107;
      border-left: 4px solid #ffc107;
      padding: 15px;
      margin: 15px 0;
    }
    .danger-box {
      background: #f8d7da;
      border: 1px solid #f5c6cb;
      border-left: 4px solid #dc3545;
      padding: 15px;
      margin: 15px 0;
    }
    .method-card {
      background: #fff;
      border: 1px solid #ddd;
      padding: 15px;
      margin: 10px 0;
      border-radius: 4px;
    }
    .method-card h4 {
      margin-top: 0;
      color: #333;
    }
  </style>
</head>
<body>
  <div class="page">
  <div class="nav-header">
    <h1>Bias Study Through Explainability</h1>
    <small>
      <a href="../../index.html">Home</a> &middot;
      <a href="../index.html">Theory</a> &middot;
      <a href="index.html">Trustworthy AI</a> &middot;
      <a href="bias-study.html">Bias Study</a>
    </small>
    <small>Detecting and analyzing bias through formal reasoning analysis</small>
  </div>

  <div class="section-intro">
    <p><strong>Because AGISystem2 shows its work, we can see exactly how definitions affect conclusions.</strong> This enables systematic bias detection by analyzing which rules impact which groups, and how changes to definitions change outcomes.</p>
  </div>

  <h2>1. Why Explainability Enables Bias Detection</h2>

  <p>In black-box AI systems, bias is detected through statistical analysis of outputs. With AGISystem2, we can go deeper:</p>

  <table>
    <tr>
      <th>Approach</th>
      <th>Black-Box Analysis</th>
      <th>Explainability-Based Analysis</th>
    </tr>
    <tr>
      <td>Detection</td>
      <td>Output disparities</td>
      <td>Rule impact analysis</td>
    </tr>
    <tr>
      <td>Root Cause</td>
      <td>Unknown</td>
      <td>Specific rules identified</td>
    </tr>
    <tr>
      <td>Intervention</td>
      <td>Retrain model</td>
      <td>Modify specific rules</td>
    </tr>
    <tr>
      <td>Verification</td>
      <td>Statistical testing</td>
      <td>Formal proof</td>
    </tr>
    <tr>
      <td>Traceability</td>
      <td>None</td>
      <td>Full audit trail</td>
    </tr>
  </table>

  <h2>2. Methodology: Definition Impact Analysis</h2>

  <p>The core insight: <strong>change a definition, observe the impact on conclusions</strong>.</p>

  <div class="analysis-box">
    <h4>The Process</h4>
    <ol>
      <li><strong>Baseline:</strong> Run queries with current definitions</li>
      <li><strong>Modification:</strong> Change a definition (add/remove/modify rule)</li>
      <li><strong>Compare:</strong> Run same queries, measure outcome changes</li>
      <li><strong>Analyze:</strong> Which groups are most affected?</li>
      <li><strong>Trace:</strong> Follow proof paths to understand why</li>
    </ol>
  </div>

  <h3>Example: Loan Eligibility Analysis</h3>

  <div class="code-block">
<span class="highlight">// Original Theory</span>
Eligible_for_loan(X) :-
    CreditScore(X) >= 700,
    Employment(X) = "full-time",
    Income(X) >= 50000.

<span class="highlight">// Baseline Results</span>
Group A (urban professionals): 85% eligible
Group B (rural workers): 42% eligible

<span class="highlight">// Modified Definition - add alternative path</span>
Eligible_for_loan(X) :-
    CreditScore(X) >= 700,
    Employment(X) = "full-time",
    Income(X) >= 50000.

Eligible_for_loan(X) :-    <span class="bias-free">// NEW: alternative criteria</span>
    CreditScore(X) >= 650,
    StableIncome(X) = true,  // 3+ years same employer
    DebtRatio(X) < 0.3.

<span class="highlight">// Results After Modification</span>
Group A: 87% eligible (+2%)
Group B: 68% eligible (+26%)  <span class="bias-free">// Significant improvement</span>
  </div>

  <div class="research-box">
    <strong>Analysis:</strong> The original definition implicitly favored Group A because "full-time employment" and "income >= 50000" correlate with urban professional jobs. Adding an alternative path based on income stability rather than amount reduced this disparity.
  </div>

  <h2>3. Types of Bias Analysis</h2>

  <div class="method-card">
    <h4>3.1 Direct Attribute Bias</h4>
    <p>Rules that explicitly reference protected attributes.</p>
    <div class="code-block">
<span class="bias-detected">// PROBLEMATIC: Direct reference to protected attribute</span>
HighRisk(X) :- Age(X) > 60.

<span class="bias-free">// BETTER: Use relevant factors instead</span>
HighRisk(X) :- HealthConditions(X) includes "chronic".
    </div>
  </div>

  <div class="method-card">
    <h4>3.2 Proxy Attribute Bias</h4>
    <p>Rules that use proxies correlated with protected attributes.</p>
    <div class="code-block">
<span class="bias-detected">// PROBLEMATIC: ZIP code is proxy for race/income</span>
PriorityService(X) :- ZIPCode(X) in [10001, 10002, 10003].

<span class="highlight">// ANALYSIS: Check correlation</span>
ZIPCode 10001-10003 → 92% Group A
ZIPCode others → 34% Group A
→ Proxy discrimination detected
    </div>
  </div>

  <div class="method-card">
    <h4>3.3 Compound Rule Bias</h4>
    <p>Individual rules are neutral, but combination creates bias.</p>
    <div class="code-block">
<span class="highlight">// Each rule seems neutral:</span>
Qualified(X) :- Degree(X) = "bachelor".
Qualified(X) :- Experience(X) >= 5.
Selected(X) :- Qualified(X), RecommendedBy(X, Y), Senior(Y).

<span class="bias-detected">// But analysis shows:</span>
Senior employees: 78% Group A
→ Recommendation requirement creates pipeline bias
    </div>
  </div>

  <div class="method-card">
    <h4>3.4 Threshold Bias</h4>
    <p>Numeric thresholds that disproportionately affect groups.</p>
    <div class="code-block">
<span class="highlight">// Threshold analysis</span>
Rule: Eligible(X) :- Score(X) >= 700

Group A mean score: 720, std: 50 → 66% eligible
Group B mean score: 680, std: 60 → 37% eligible

<span class="highlight">// Sensitivity analysis</span>
At threshold 680: Group A 75%, Group B 50%
At threshold 720: Group A 50%, Group B 25%
At threshold 700: Group A 66%, Group B 37%

→ Threshold choice significantly impacts disparity
    </div>
  </div>

  <h2>4. Counterfactual Fairness Analysis</h2>

  <p>For each decision, ask: "Would the outcome change if only the protected attribute were different?"</p>

  <div class="code-block">
<span class="highlight">// Original case</span>
Person: Alice, Age: 35, Gender: F, Experience: 10yr, Degree: PhD
Decision: HIRED
Proof path: Qualified via degree → Interviewed → Selected

<span class="highlight">// Counterfactual: Change only gender</span>
Person: Alice', Age: 35, Gender: M, Experience: 10yr, Degree: PhD
Decision: HIRED
Proof path: Qualified via degree → Interviewed → Selected

<span class="bias-free">Result: COUNTERFACTUALLY FAIR</span>
(Same outcome despite protected attribute change)

<span class="highlight">// Different case</span>
Person: Bob, Age: 62, Experience: 30yr, Health: good
Decision: NOT_PROMOTED
Proof path: Age > 60 → RetirementTrack → NotPromotionEligible

<span class="highlight">// Counterfactual</span>
Person: Bob', Age: 45, Experience: 30yr, Health: good
Decision: PROMOTED
Proof path: Experience > 20 → SeniorTrack → PromotionEligible

<span class="bias-detected">Result: COUNTERFACTUALLY UNFAIR</span>
(Different outcome when only age changed)
<span class="bias-detected">Problematic rule: Age > 60 → RetirementTrack</span>
  </div>

  <h2>5. Systematic Bias Detection Process</h2>

  <h3>Step 1: Define Protected Attributes</h3>
  <div class="code-block">
ProtectedAttributes = [Age, Gender, Race, Disability, Religion]
  </div>

  <h3>Step 2: Identify Rules Referencing Protected Attributes</h3>
  <div class="code-block">
<span class="highlight">// Scan all rules</span>
DirectReferences:
  - Rule 23: Age > 60 → RetirementEligible
  - Rule 47: Gender = F → MaternityEligible

ProxyReferences (via correlation analysis):
  - Rule 12: ZIPCode in [...] (correlated with Race)
  - Rule 31: PartTime = true (correlated with Gender)
  </div>

  <h3>Step 3: Run Counterfactual Analysis</h3>
  <div class="code-block">
For each decision D:
  For each protected attribute A:
    D' = counterfactual(D, flip A)
    If outcome(D) ≠ outcome(D'):
      Flag as potentially unfair
      Record: (D, A, rule_path_diff)
  </div>

  <h3>Step 4: Aggregate and Report</h3>
  <div class="code-block">
<span class="highlight">Bias Report Summary</span>
─────────────────────────────────────
Total decisions analyzed: 10,000
Counterfactually unfair: 847 (8.5%)

By protected attribute:
  Age: 412 cases (4.1%)
  Gender: 203 cases (2.0%)
  ZIPCode (proxy): 232 cases (2.3%)

Most impactful rules:
  1. Rule 23 (Age > 60): 398 affected decisions
  2. Rule 12 (ZIPCode): 232 affected decisions
  3. Rule 31 (PartTime): 189 affected decisions
  </div>

  <h2>6. Intervention and Verification</h2>

  <div class="warning-box">
    <strong>The Fix Cycle:</strong>
    <ol>
      <li>Identify biased rule</li>
      <li>Propose modification</li>
      <li>Re-run analysis on historical data</li>
      <li>Verify bias reduction without functionality loss</li>
      <li>Deploy and monitor</li>
    </ol>
  </div>

  <div class="code-block">
<span class="highlight">// Original biased rule</span>
HighRisk(X) :- Age(X) > 60.

<span class="highlight">// Proposed fix</span>
HighRisk(X) :-
    MedicalConditions(X) includes "high-risk",
    NOT ActiveLifestyle(X).

<span class="highlight">// Verification</span>
Old rule: 100% of Age>60 flagged as HighRisk
New rule: 34% of Age>60 flagged (those with actual risk factors)
          12% of Age<60 flagged (those with risk factors)

Disparity reduction: 66% → 22%
False positive reduction: 45%
  </div>

  <h2>7. Continuous Monitoring</h2>

  <p>Bias can emerge over time as data distributions shift:</p>

  <div class="analysis-box">
    <h4>Monitoring Dashboard Metrics</h4>
    <ul>
      <li>Decision disparity ratios by protected group</li>
      <li>Counterfactual fairness scores</li>
      <li>Rule impact distributions</li>
      <li>Proxy correlation tracking</li>
      <li>Threshold sensitivity alerts</li>
    </ul>
  </div>

  <h2>8. Limitations and Considerations</h2>

  <div class="danger-box">
    <strong>Important Caveats:</strong>
    <ul>
      <li><strong>Theory completeness:</strong> Analysis is only as good as the encoded rules</li>
      <li><strong>Proxy detection:</strong> Some proxies may not be obvious without domain expertise</li>
      <li><strong>Fairness definitions:</strong> Different fairness criteria may conflict</li>
      <li><strong>Business necessity:</strong> Some disparities may be legally justified</li>
      <li><strong>Data quality:</strong> Biased input data leads to biased analysis</li>
    </ul>
  </div>

  <h2>9. Research Directions</h2>

  <div class="research-box">
    <strong>Open Questions:</strong>
    <ul>
      <li>Automatic proxy detection in complex rule networks</li>
      <li>Multi-criteria fairness optimization</li>
      <li>Causal inference integration for better counterfactuals</li>
      <li>Federated bias analysis across organizations</li>
      <li>Real-time bias monitoring at scale</li>
    </ul>
  </div>

  <h2>Related Documentation</h2>

  <ul>
    <li><a href="index.html">Trustworthy AI Overview</a></li>
    <li><a href="explainability.html">Explainability</a></li>
    <li><a href="synthetic-data.html">Synthetic Data Generation</a></li>
    <li><a href="compliance.html">Compliance & Verification</a></li>
    <li><a href="research.html">Research Directions</a></li>
  </ul>

  <div class="footer-nav">
    <p>
      <a href="synthetic-data.html">&larr; Synthetic Data</a> |
      <a href="index.html">Trustworthy AI Overview</a>
    </p>
  </div>
  </div>
</body>
</html>
