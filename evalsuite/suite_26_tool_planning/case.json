{
  "id": "suite_26_tool_planning",
  "name": "Tool Chain Planning - Web Scraping Pipeline",
  "description": "Tests ability to plan a multi-step tool chain for web scraping. Given a goal like 'get processed data from URL', system must find the sequence: fetch→parse→transform→save, resolving dependencies and parameter passing between steps.",

  "theory": {
    "natural_language": "TOOL DEFINITIONS: The fetch_url tool takes a url parameter and produces raw_html output. The parse_html tool takes raw_html parameter and produces dom_tree output. The extract_data tool takes dom_tree and selector parameters and produces extracted_list output. The transform_json tool takes extracted_list parameter and produces json_data output. The save_file tool takes json_data and filepath parameters and produces saved_file output. The compress_archive tool takes saved_file parameter and produces archive output. COMPOSITION RULES: To get dom_tree you must first fetch_url then parse_html. To get extracted_list you must first have dom_tree then extract_data. To get json_data you must first have extracted_list then transform_json. To get saved_file you must first have json_data then save_file. To get archive you must first have saved_file then compress_archive. EXECUTION SEQUENCE: Step 1 is fetch_url with url parameter. Step 2 is parse_html with raw_html from step 1. Step 3 is extract_data with dom_tree from step 2 and selector config. Step 4 is transform_json with extracted_list from step 3. Step 5 is save_file with json_data from step 4 and filepath config. Step 6 is compress_archive with saved_file from step 5.",
    "expected_facts": [
      "fetch_url TAKES url",
      "fetch_url PRODUCES raw_html",
      "parse_html TAKES raw_html",
      "parse_html PRODUCES dom_tree",
      "extract_data TAKES dom_tree",
      "extract_data TAKES selector",
      "extract_data PRODUCES extracted_list",
      "transform_json TAKES extracted_list",
      "transform_json PRODUCES json_data",
      "save_file TAKES json_data",
      "save_file TAKES filepath",
      "save_file PRODUCES saved_file",
      "compress_archive TAKES saved_file",
      "compress_archive PRODUCES archive",
      "dom_tree REQUIRES_FIRST fetch_url",
      "dom_tree REQUIRES_THEN parse_html",
      "extracted_list REQUIRES_FIRST dom_tree",
      "extracted_list REQUIRES_THEN extract_data",
      "json_data REQUIRES_FIRST extracted_list",
      "json_data REQUIRES_THEN transform_json",
      "saved_file REQUIRES_FIRST json_data",
      "saved_file REQUIRES_THEN save_file",
      "archive REQUIRES_FIRST saved_file",
      "archive REQUIRES_THEN compress_archive",
      "step_1 EXECUTES fetch_url",
      "step_1 WITH_PARAM url",
      "step_2 EXECUTES parse_html",
      "step_2 INPUT_FROM step_1",
      "step_3 EXECUTES extract_data",
      "step_3 INPUT_FROM step_2",
      "step_3 WITH_PARAM selector",
      "step_4 EXECUTES transform_json",
      "step_4 INPUT_FROM step_3",
      "step_5 EXECUTES save_file",
      "step_5 INPUT_FROM step_4",
      "step_5 WITH_PARAM filepath",
      "step_6 EXECUTES compress_archive",
      "step_6 INPUT_FROM step_5"
    ]
  },

  "queries": [
    {
      "id": "q1",
      "natural_language": "PLAN STEP 1: What is the first tool to execute and what parameter does it need?",
      "expected_dsl": "@q1 FACTS_MATCHING step_1 EXECUTES ?",
      "expected_answer": {
        "natural_language": "Step 1 executes fetch_url with url parameter.",
        "truth": "LIST",
        "explanation": "First step identification with parameter"
      }
    },
    {
      "id": "q2",
      "natural_language": "DEPENDENCY CHECK: What must be produced before parse_html can run?",
      "expected_dsl": "@q2 FACTS_MATCHING parse_html TAKES ?",
      "expected_answer": {
        "natural_language": "parse_html takes raw_html (which comes from fetch_url).",
        "truth": "LIST",
        "explanation": "Dependency resolution"
      }
    },
    {
      "id": "q3",
      "natural_language": "PLAN STEP 3: What does extract_data need as inputs?",
      "expected_dsl": "@q3 FACTS_MATCHING extract_data TAKES ?",
      "expected_answer": {
        "natural_language": "extract_data takes dom_tree and selector.",
        "truth": "LIST",
        "explanation": "Multi-input tool requirements"
      }
    },
    {
      "id": "q4",
      "natural_language": "DATA FLOW: Where does step_4 get its input from?",
      "expected_dsl": "@q4 FACTS_MATCHING step_4 INPUT_FROM ?",
      "expected_answer": {
        "natural_language": "Step 4 gets input from step 3.",
        "truth": "LIST",
        "explanation": "Data flow between steps"
      }
    },
    {
      "id": "q5",
      "natural_language": "GOAL DECOMPOSITION: What sequence produces json_data?",
      "expected_dsl": "@q5 FACTS_MATCHING json_data REQUIRES_FIRST ?",
      "expected_answer": {
        "natural_language": "json_data requires first having extracted_list, then applying transform_json.",
        "truth": "LIST",
        "explanation": "Backward chaining from goal"
      }
    },
    {
      "id": "q6",
      "natural_language": "PARAMETER MAPPING: Which steps need configuration parameters (not just data flow)?",
      "expected_dsl": "@q6 FACTS_MATCHING ? WITH_PARAM ?",
      "expected_answer": {
        "natural_language": "Step 1 needs url, step 3 needs selector, step 5 needs filepath.",
        "truth": "LIST",
        "explanation": "Configuration vs data parameters"
      }
    },
    {
      "id": "q7",
      "natural_language": "FINAL STEP: What produces the archive output?",
      "expected_dsl": "@q7 FACTS_MATCHING ? PRODUCES archive",
      "expected_answer": {
        "natural_language": "compress_archive produces archive.",
        "truth": "LIST",
        "explanation": "Final step identification"
      }
    },
    {
      "id": "q8",
      "natural_language": "FULL CHAIN: What tool does step_6 execute?",
      "expected_dsl": "@q8 FACTS_MATCHING step_6 EXECUTES ?",
      "expected_answer": {
        "natural_language": "Step 6 executes compress_archive.",
        "truth": "LIST",
        "explanation": "Last step in the execution plan"
      }
    }
  ],

  "tags": ["tool_planning", "sequencing", "web_scraping", "pipeline", "data_flow", "parameter_passing"]
}
